catalog: NexusAssistantArchitecture

entity: NexusAssistantService
role: platform
purpose:
    - Single deployable service providing specification parsing and querying
    - Contains @NexusParser, @ValidationEngine, @SpecificationStore, @KnowledgeGraph, @QueryProcessor, @APIGateway, @MCPServer, @CodeParser, and @TraceabilityMatcher
    - Includes LLM-powered traceability components: @SemanticMatcher, @LLMReasoner, @TraceValidator, @ExplanationGenerator, @FeedbackLearner, @TraceStorage
    - Exposes REST API via @APIGateway and MCP protocol via @MCPServer
    - Discovers implicit traceability between specifications and source code using hybrid embeddings + LLM reasoning
    - Persists trace links to disk avoiding expensive LLM validation on every restart
properties:
    deploymentModel: CloudService
    runtimeEnvironment: Python 
    

entity: ParsedSpecification
role: struct
purpose:
    - Structured representation of a parsed Nexus specification file
    - Output from @NexusParser containing all elements of a .nxs file
properties:
    catalogName: String, name declared in catalog statement
    filePath: String, source file path
    imports: collection of @ImportItem, imported module declarations
    entities: collection of @EntityDefinition, parsed entity definitions
    rules: collection of @NamedBlock, business rules with type rule
    scenarios: collection of @NamedBlock, scenarios with type scenario
    parseTimestamp: Number, when file was parsed in unix timestamp
    specificationHash: String, content hash for change detection

entity: EntityDefinition
role: struct
purpose:
    - Represents a parsed entity from Nexus specification
    - Contains all entity metadata including role, purpose, properties, and actions
properties:
    entityName: String, entity identifier
    catalog: String, the catalog to which the entity belongs
    role: String, entity role (platform, module, component, service, actor, struct, etc)
    purposes: collection of @NamedBlock, entity purposes with type purpose
    properties: collection of @NamedBlock, entity properties with type property
    actions: collection of @NamedBlock, entity actions with type action

entity: ImportItem
role: struct
purpose:
    - Represents an import declaration from a Nexus specification file
    - Contains module path and optional alias
properties:
    modulePath: String, the qualified module path being imported
    alias: String, optional alias name for the imported module

entity: Statement
role: struct
purpose:
    - Atomic unit of text that may reference entities
properties:
    text: String, the actual text content
    references: collection of String, referenced entity names including properties and actions (e.g., entity.property)

entity: NamedBlock
role: struct
purpose:
    - Named container for one or more statements
    - Used for purposes, properties, actions, rules, scenarios, and explicit relations
properties:
    name: String, identifier for the block
    relationType: one of {purpose, property, action, rule, scenario, explicit}, what kind of block this is
    statements: collection of @Statement, the content

entity: Relation
role: struct
purpose:
    - Represents a typed relationship between entities in @KnowledgeGraph
    - Can involve multiple entities without implied directionality
    - Derived from @NamedBlock references during parsing
properties:
    entities: collection of String, entity names participating in this relation
    relationType: one of {purpose, property, action, rule, scenario, explicit}, how the entities are related
    statement: @Statement, the statement that created this relation 

rule: RelationReference
Each @Relation that is derived from @EntityDefinition must contains that entity as one of its references 

entity: NexusParser
role: component
purpose:
    - Parses Nexus language files (.nxs) into @ParsedSpecification structures
    - Uses @ValidationEngine to ensure syntax and semantic correctness
    - Populates @KnowledgeGraph with parsed entities, relations, rules, and scenarios
properties:
    parserLibrary: Lark, Python parsing library for grammar-based parsing
actions:
    parseFile: Reads and parses a .nxs file into @ParsedSpecification
    validateSyntax: Checks for syntax errors and returns validation results

entity: KnowledgeGraph
role: module
purpose:
    - Central repository maintaining in-memory graph of all parsed specification elements
    - Stores entities and typed relations (@Relation) between them (purpose, property, action, rule, scenario, explicit)
    - Maintains three-layer model: product views, system design views, and component implementations
    - Stores @CodeEntity objects and @TraceLink objects for code traceability
    - Provides millisecond-speed lookups and traversals across specifications and code using optimized in-memory indexes
    - Enables rapid entity discovery through efficient filtering by catalog, layer, and role
properties:
    indexingStrategy: InMemory
    enableCrossFileLinks: Boolean, whether to link entities across different specification files, default true
    threeLayerModel: Boolean, maintains ProductView, SystemDesignView, and ComponentImplementation separation, default true
    codeEntities: collection of @CodeEntity, parsed code elements indexed by qualified name
    traceLinks: collection of @TraceLink, discovered semantic relationships between specs and code
actions:
    addEntity: Inserts entity node with its properties and actions into graph
    addRelation: Creates typed edge between entity nodes with relation type (purpose, property, action, rule, scenario, explicit)
    addCodeEntity: Inserts @CodeEntity from parsed source code
    addTraceLink: Stores @TraceLink discovered by @TraceabilityMatcher
    getEntity: Returns entity by name
    getCodeEntity: Returns @CodeEntity by qualified name
    getRelations: Returns all relations for an entity, optionally filtered by relation type
    getTraceLinks: Returns @TraceLink objects for an entity (forward to next layer or backward to previous layer)
    traceChain: Follows multiple @TraceLink objects across layers to trace from any layer to any other layer
    findPath: Discovers paths between two entities through design layer
    getEntities: Returns all entities, optionally filtered by catalog, layer, or role
    getAllRelations: Returns all relations
    getCatalogs: Returns list of all catalogs with entity counts and layer information
    filterEntitiesByRole: Returns entities matching specific role (actor, service, component, etc)
    removeCodeEntitiesFromFile: Removes all code entities from a specific file (for reindexing)

entity: QueryProcessor
role: component
purpose:
    - Interprets developer and AI agent queries with deep understanding of intent and context
    - Prioritizes accuracy and completeness of results over response speed in all search operations
    - Searches @KnowledgeGraph comprehensively for relevant entities and relationships using both exact matching and semantic search
    - Optimizes for speed through embedding caching and vector search without compromising result quality
    - Deeply understands entity purposes, properties, actions, and relationships for accurate contextual matching
    - Searches across multiple layers to ensure complete coverage of relevant entities
    - Ranks results by semantic relevance with appropriate thresholds to balance precision and recall
    - Handles traceability queries across specifications and code using @TraceLink objects
    - Supports natural language queries through embedding-based semantic matching
    - Enables entity discovery and exploration through filtering and browsing
    - Returns query results as JSON
properties:
    queryLanguage: one of {Natural, Structured}
    maxResults: Number, maximum results to return after ranking, default 10
    semanticSearchEnabled: Boolean, enables embedding-based semantic search for natural language queries, default true
    embeddingService: String, OpenAI API for text-embedding-3-small model, shared with @TraceabilityMatcher
    semanticThreshold: Number, minimum cosine similarity for semantic query matches tuned to balance precision and recall, default 0.6
    cache: @EmbeddingCache, shared cache with @TraceabilityMatcher for query embeddings
    intentParser: LLM, uses OpenAI chat completion for natural language query understanding with structured output, falls back to regex patterns if LLM unavailable
    llmModel: String, model for query intent parsing, default gpt-4o-mini
    vectorStore: collection, pre-indexed entity embeddings from @TraceabilityMatcher enabling fast similarity search
    rankingWeights: struct, configurable weights for ranking factors tuned for accuracy (similarity 0.5, richness 0.2, centrality 0.2, layer_match 0.1)
    parallelSearchEnabled: Boolean, enables concurrent search across multiple layers without compromising completeness, default true
    queryContextCache: collection, maintains recent query context for iterative refinement
    minConfidenceScore: Number, minimum composite confidence score for result inclusion ensuring quality, default 0.3
    exhaustiveSearch: Boolean, when true searches all entities before filtering ensuring no relevant results missed, default true
actions:
    parseQuery: Extracts intent and entities from user query using @intentParser LLM with regex fallback, returns structured QueryIntent with query_type, entity_names, layer filters, and parameters
    determineScope: Identifies which specification layers to search based on query context
    executeQuery: Queries @KnowledgeGraph and returns results
    semanticSearch: Generates embedding for natural language query and finds semantically similar entities using cosine similarity
    matchQueryIntent: Analyzes query text to understand whether user wants entities, relationships, layer browsing, or traceability
    rankResults: Scores and orders results by semantic relevance to query
    traceToCode: Follows @TraceLink objects from specification entity to implementing code
    traceToSpec: Follows @TraceLink objects backward from code to specification requirements
    assessCoverage: Identifies specifications without corresponding code (gaps in implementation)
    discoverEntities: Lists entities from @KnowledgeGraph filtered by catalog, layer, role, or semantic context
    exploreEntity: Retrieves detailed entity information including purpose, properties, actions, and relationships from @KnowledgeGraph
    browseEntityGraph: Navigates entity relationships enabling exploration of system structure and dependencies
    findRelevantEntities: Rapidly retrieves contextually relevant entities by generating query embedding, searching @KnowledgeGraph vector store with layer filtering, and matching against entity purposes, properties, actions, and relationships
    rankByRelevance: Applies multi-factor ranking algorithm considering cosine similarity score, entity metadata richness (number of properties and actions), relationship centrality (in/out-degree in graph), layer match to query context, and returns sorted results with relevance explanations
    crossLayerSearch: Searches multiple layers (product, design, implementation, code) in parallel, retrieves results from each, identifies cross-layer connections via @TraceLink objects, and unifies results showing layer relationships
    extractQueryConcepts: Analyzes natural language query to extract key concepts, domain terms, and intent signals for enhanced semantic matching

entity: SpecificationStore
role: platform
purpose:
    - Reads Nexus specification files from filesystem
    - Watches for file changes and triggers @NexusParser to re-parse modified files
properties:
    storageType: FileSystem
    watchForChanges: Boolean, default true
actions:
    loadSpecification: Reads specification from filesystem
    watchFile: Monitors file for changes
    listSpecifications: Returns all available specifications

entity: APIGateway
role: component
purpose:
    - Exposes REST API for external integrations
    - Routes requests to @QueryProcessor
properties:
    authenticationRequired: Boolean, default false
actions:
    handleRequest: Processes incoming API request
    routeToService: Forwards to @QueryProcessor
    formatResponse: Standardizes JSON responses

entity: MCPServer
role: component
purpose:
    - Implements Model Context Protocol server for AI agent integration
    - Exposes @QueryProcessor capabilities through MCP protocol including entity discovery and exploration
    - Enables both internal and external AI agents to query specifications and discover system structure
properties:
    protocolVersion: String, MCP protocol version supported, default 1.0
    transportType: one of {stdio, http}, communication transport mechanism, default stdio
    toolsEnabled: Boolean, whether to expose MCP tools, default true
actions:
    handleMCPRequest: Processes incoming MCP protocol request
    exposeTool: Registers @QueryProcessor operations as MCP tools including discoverEntities, exploreEntity, and browseEntityGraph
    formatMCPResponse: Serializes results in MCP protocol format

entity: ValidationEngine
role: component
purpose:
    - Validates specifications against Nexus language rules
    - Ensures referenced entities exist
    - Checks relation cardinality constraints
properties:
    strictMode: Boolean, enforce all rules strictly, default true
actions:
    validateEntity: Checks entity definition correctness
    validateReferences: Ensures all referenced entities exist
    validateRelations: Verifies relation constraints are met
    reportViolations: Returns collection of validation errors

entity: CodeEntity
role: struct
purpose:
    - Structured representation of a parsed code element (file, class, function, or module)
    - Extracted from source code by @CodeParser using AST parsing
    - Contains semantic information for embedding generation by @TraceabilityMatcher
properties:
    entityType: one of {file, class, function, module}, type of code element
    qualifiedName: String, fully qualified identifier (e.g., "payment.gateway.PaymentService.process_payment")
    filePath: String, absolute path to source file
    startLine: Number, beginning line number in file
    endLine: Number, ending line number in file
    sourceCode: String, actual implementation code
    docstring: String, extracted documentation or comments, may be empty
    language: String, programming language (python, typescript, etc)
    parentContext: String, parent class or module name for context
    signature: String, function/method signature including parameters

entity: ParsedCodeRepository
role: struct
purpose:
    - Collection of @CodeEntity objects representing parsed source code repository
    - Output from @CodeParser after scanning codebase
    - Stored in @KnowledgeGraph alongside specification entities
properties:
    repositoryPath: String, root directory of code repository
    language: String, primary programming language
    entities: collection of @CodeEntity, all parsed code elements
    fileIndex: collection of String, paths of files that were parsed
    parseTimestamp: Number, when repository was last parsed
    contentHash: String, hash of repository state for change detection

entity: CodeParser
role: component
purpose:
    - Parses source code files into @CodeEntity structures using language-specific AST parsers
    - Extracts classes, functions, and modules at appropriate granularity
    - Enriches entities with contextual information for better semantic matching
    - Filters out trivial or private elements that shouldn't be traced
properties:
    language: String, target programming language
    astParser: component, language-specific parser (ast module for Python, ts-morph for TypeScript)
    granularity: one of {function, class, file}, parsing level, default function
actions:
    parseFile: Parses single file into collection of @CodeEntity objects
    parseRepository: Scans entire repository and returns @ParsedCodeRepository
    enrichWithContext: Adds parent class/module context to function entities
    shouldIndex: Filters out private functions, trivial getters, or test helpers
    extractSignature: Generates function signature including parameter types

entity: TraceLink
role: struct
purpose:
    - Represents discovered semantic relationship between any two entities across layers
    - Supports product-to-design, design-to-implementation, implementation-to-code, and all reverse directions
    - Created by @TraceabilityMatcher through hybrid approach combining embedding similarity and LLM reasoning
    - Includes human-readable explanation generated by @LLMReasoner for why the connection exists
    - Stored in @KnowledgeGraph to enable bidirectional tracing across all layers
properties:
    sourceQualifiedName: String, source entity identifier (e.g., "NexusAssistant.PaymentFlow")
    sourceLayer: one of {product, design, implementation, code}, source layer
    targetQualifiedName: String, target entity identifier (e.g., "PaymentDesign.PaymentGateway" or "payment.gateway.PaymentService")
    targetLayer: one of {product, design, implementation, code}, target layer
    confidence: Number, composite confidence score between 0.0 and 1.0 combining semantic similarity and LLM validation
    embeddingSimilarity: Number, raw cosine similarity score from embedding comparison
    llmConfidence: Number, LLM reasoning confidence score for this connection
    rationale: String, human-readable explanation generated by @LLMReasoner explaining why entities are related and how they connect
    validationStatus: one of {validated, candidate, rejected}, LLM validation outcome
    direction: one of {forward, backward}, tracing direction relative to product-to-code flow
    discoveredTimestamp: Number, when link was generated
    embeddingModel: String, model used for semantic matching
    llmModel: String, LLM model used for validation and explanation

entity: TraceabilityMatcher
role: component
purpose:
    - Discovers implicit semantic relationships across all layers using hybrid approach combining embeddings and LLM reasoning
    - Uses @ContextEnricher to generate rich, comprehensive entity summaries including related entities and layer semantics before embedding
    - Generates embeddings from enriched context capturing complete architectural understanding not just isolated descriptions
    - Uses @SemanticMatcher for fast embedding-based candidate generation
    - Applies @LLMReasoner with enriched entity context to validate candidates and discover non-obvious connections that embeddings miss
    - Generates human-readable explanations for trace links via @ExplanationGenerator
    - Resolves ambiguities when multiple entities appear similar using LLM contextual understanding
    - Discovers multi-hop trace paths through relationship chains that direct similarity cannot find
    - Learns from user feedback through @FeedbackLearner to continuously improve trace quality
    - Persists discovered trace links via @TraceStorage for instant loading on restart
    - Populates shared vectorStore enabling @QueryProcessor to perform rapid semantic queries
    - Stores discovered @TraceLink objects with confidence scores and explanations in @KnowledgeGraph
    - Maintains flexible traceability: product→design (required), design→implementation or design→code (alternative paths), implementation→code
properties:
    contextEnricher: @ContextEnricher, enriches entity context before embedding generation and LLM validation
    semanticMatcher: @SemanticMatcher, embedding-based similarity matching for candidate generation
    llmReasoner: @LLMReasoner, validates candidates and discovers non-obvious connections
    traceValidator: @TraceValidator, scores confidence using multiple quality signals
    explanationGenerator: @ExplanationGenerator, creates human-readable rationales for trace links
    feedbackLearner: @FeedbackLearner, learns from user validation to improve discovery
    traceStorage: @TraceStorage, persists trace links to disk with change detection
    embeddingService: String, OpenAI API for text-embedding-3-small model
    embeddingDimensions: Number, vector size, 1536 for text-embedding-3-small
    embeddingSimilarityThreshold: Number, minimum cosine similarity for candidate generation, default 0.6
    llmConfidenceThreshold: Number, minimum LLM confidence for validated trace link, default 0.7
    llmModel: String, LLM for validation and reasoning, default gpt-4o-mini
    cache: @EmbeddingCache, content-based caching to avoid redundant API calls
    vectorStore: collection, stores embeddings indexed by qualified name and layer
    feedbackStore: collection, stores user validation history for learning
    contentHashes: collection, tracks entity content hashes for cache invalidation
actions:
    generateEmbedding: Calls embedding service to create vector representation of text
    indexSpecEntity: Uses @ContextEnricher to gather complete entity context with related entities and layer semantics, then creates rich embedding from enriched summary
    indexCodeEntity: Uses @ContextEnricher to gather code entity context including parent information and related specifications, then creates embedding from enriched summary
    findCandidates: Uses @SemanticMatcher to find candidate matches above embedding similarity threshold
    validateCandidate: Uses @ContextEnricher to get full enriched context for both entities, then applies @LLMReasoner to confirm if candidate trace link is valid
    disambiguateCandidates: Uses @LLMReasoner to resolve ambiguity when multiple entities have similar embeddings
    reasonAboutIndirectLinks: Uses @LLMReasoner to follow relationship chains and discover multi-hop connections
    generateExplanation: Calls @ExplanationGenerator to create rationale for trace link
    scoreConfidence: Uses @TraceValidator to compute composite confidence from embedding similarity and LLM validation
    createTraceLink: Generates @TraceLink with confidence score, validation status, and human-readable rationale
    discoverLayerLinks: Discovers links following valid layer transitions using hybrid embedding + LLM approach with enriched entity context
    discoverAllLinks: Checks @TraceStorage cache validity, loads cached trace links if entities unchanged, otherwise indexes all entities using enriched context and discovers trace links across all layers with LLM validation then saves to cache
    processFeedback: Records user validation decisions through @FeedbackLearner to improve future discovery
    populateVectorStore: Builds optimized vectorStore index for @QueryProcessor with all entity embeddings organized by layer and catalog

entity: EmbeddingCache
role: component
purpose:
    - Caches generated embeddings by content hash to avoid redundant API calls
    - Implements full file reindex strategy with content-based caching for efficiency
    - Stores cache in memory with optional persistence to disk
properties:
    storageType: one of {memory, disk}, cache storage mechanism, default memory
    maxCacheSize: Number, maximum cached embeddings, default 10000
    cachePath: String, file path for persistent cache, used when storageType is disk
actions:
    getOrGenerate: Returns cached embedding if content unchanged, generates new one otherwise
    computeContentHash: Generates SHA256 hash of entity content for cache key
    invalidate: Removes cached embedding when source content changes
    persist: Writes in-memory cache to disk for persistence across restarts

entity: SemanticMatcher
role: component
purpose:
    - Provides fast embedding-based similarity matching as first stage of trace discovery
    - Generates candidate trace links for @TraceabilityMatcher validation
    - Uses vector search to find entities above similarity threshold
properties:
    vectorStore: collection, indexed embeddings organized by layer
    candidateThreshold: Number, minimum similarity for candidate generation, default 0.6
actions:
    findSimilarEntities: Performs cosine similarity search filtered by valid target layers
    generateCandidates: Returns list of potential trace links above threshold with raw similarity scores

entity: LLMReasoner
role: component
purpose:
    - Applies large language model reasoning to validate trace links and discover non-obvious connections
    - Understands context, intent, and logical relationships beyond embedding similarity
    - Uses layer semantics from @LayerSemantics to understand what each layer represents and expected transition patterns
    - Analyzes enriched entity context including purposes, properties, actions, related entities, and code behavior for validation
    - Follows chains of relationships to discover indirect multi-hop connections
properties:
    llmService: String, OpenAI API for chat completions
    llmModel: String, model for reasoning, default gpt-4o-mini
    layerSemantics: @LayerSemantics, provides layer descriptions and transition semantics for validation prompts
    validationPromptTemplate: String, structured prompt for trace validation including layer semantics
    reasoningTemperature: Number, LLM temperature for deterministic reasoning, default 0.1
    maxReasoningTokens: Number, token limit for LLM responses, default 500
actions:
    validateTraceLink: Analyzes enriched specification and code/spec context with layer semantics to confirm if candidate link is valid
    explainConnection: Generates detailed reasoning about why entities are related considering layer meanings
    disambiguateEntities: Determines correct match when multiple candidates have similar embeddings using layer-aware reasoning
    discoverIndirectLinks: Follows relationship chains to find multi-hop trace paths
    reasonAboutBehavior: Analyzes code logic flow to match against specification intent
    buildValidationPrompt: Constructs LLM prompt including enriched entity context and layer transition semantics

entity: TraceValidator
role: component
purpose:
    - Scores trace link confidence based on multiple quality signals
    - Identifies high-confidence traces and flags uncertain connections for review
    - Combines embedding similarity with LLM validation scores
properties:
    embeddingWeight: Number, weight for embedding similarity score, default 0.4
    llmWeight: Number, weight for LLM confidence score, default 0.6
    minCompositeConfidence: Number, minimum score for trace acceptance, default 0.7
actions:
    computeConfidence: Calculates weighted composite score from embedding and LLM signals
    assessQuality: Evaluates trace link against quality criteria
    flagForReview: Identifies low-confidence traces needing human validation
    categorizeConfidence: Assigns confidence level (high, medium, low) based on thresholds

entity: ExplanationGenerator
role: component
purpose:
    - Creates human-readable justifications explaining why trace links exist
    - Helps developers understand traceability rationale, not just see connections
    - Generates context-aware explanations based on entity semantics and LLM reasoning
properties:
    llmService: String, OpenAI API for explanation generation
    llmModel: String, model for natural language generation, default gpt-4o-mini
    explanationTemplate: String, template for structured rationale generation
    maxExplanationLength: Number, character limit for explanations, default 500
actions:
    generateRationale: Creates explanation describing why specification connects to code
    describeConnection: Explains how entities relate based on purposes, properties, and actions
    formatExplanation: Structures rationale in readable format with key evidence points

entity: ContextEnricher
role: component
purpose:
    - Enriches entity context by gathering related entities and architectural information from @KnowledgeGraph
    - Generates layer-specific semantic context explaining what each layer represents
    - Creates comprehensive entity summaries including relationships and architectural role
    - Provides enriched context for both embedding generation and LLM validation
properties:
    knowledgeGraph: @KnowledgeGraph, reference to knowledge graph for retrieving related entities
    layerSemantics: @LayerSemantics, provides layer descriptions and transition semantics
    maxRelatedEntities: Number, maximum number of related entities to include, default 5
    includeRelationships: Boolean, whether to include entity relationships in enriched context, default true
    relationshipDepth: Number, how many hops to traverse for related entities, default 1
actions:
    enrichSpecEntity: Gathers complete context for specification entity including purposes, properties, actions, related entities, layer semantics, and architectural role
    enrichCodeEntity: Gathers complete context for code entity including docstring, signature, parent context, file location, and related specifications if available
    getLayerSemantics: Retrieves layer description and semantics from @LayerSemantics for specific layer
    getRelatedEntityContext: Queries @KnowledgeGraph to get related entities and their relationship types
    formatEnrichedSummary: Structures enriched context into text format suitable for embedding or LLM consumption

entity: LayerSemantics
role: component
purpose:
    - Provides semantic descriptions of what each layer represents in the system
    - Defines valid layer transitions and what they mean
    - Supplies validation criteria specific to each layer transition type
    - Used by @ContextEnricher and @LLMReasoner to understand layer semantics
properties:
    layerDescriptions: collection, maps layer names to semantic descriptions explaining what each layer represents
    transitionTemplates: collection, describes expected relationships between each valid layer pair
    validationCriteria: collection, layer-specific criteria for validating trace links
    validTransitions: collection, defines which layer transitions are valid (product→design, design→implementation, design→code, implementation→code)
actions:
    getLayerDescription: Returns semantic description of what a specific layer represents
    getTransitionSemantics: Returns description of expected relationship between source and target layers
    getValidationCriteria: Returns criteria for validating trace links for specific layer transition
    isValidTransition: Checks if transition between two layers is valid

entity: FeedbackLearner
role: component
purpose:
    - Learns from user feedback to continuously improve trace discovery accuracy
    - Stores validation decisions and adapts reasoning patterns
    - Reduces false positives over time without manual retraining
properties:
    feedbackStore: collection, stores user validation history with context
    learningEnabled: Boolean, enables adaptive improvement, default true
    feedbackWeight: Number, influence of feedback on future decisions, default 0.2
actions:
    recordFeedback: Stores user validation decision (correct, incorrect, uncertain) with trace context
    analyzeFeedback: Identifies patterns in validated vs rejected traces
    adaptThresholds: Adjusts confidence thresholds based on feedback patterns
    updateReasoningPatterns: Refines LLM prompts based on what makes good traces
    generateInsights: Reports on trace quality improvements from learning

entity: TraceStorage
role: component
purpose:
    - Persists discovered @TraceLink objects to disk for instant loading on restart
    - Tracks SHA256 content hashes of entity summaries to detect specification or code changes
    - Invalidates entire trace link cache when any entity is added, removed, or modified triggering full re-discovery
    - Eliminates expensive LLM validation re-runs when nothing has changed
    - Works with @EmbeddingCache which retains embeddings for unchanged entities enabling efficient re-discovery
    - Stores cache in .trace_cache directory with JSON serialization
properties:
    storagePath: String, directory for cache files, default .trace_cache
    traceLinksFile: String, JSON file for serialized @TraceLink collection
    contentHashesFile: String, JSON file storing entity content hashes for change detection
    enabled: Boolean, enables trace link persistence, default true
actions:
    saveTraceLinks: Persists collection of @TraceLink objects with entity content hashes to disk
    loadTraceLinks: Loads cached trace links and content hashes from disk if files exist
    isCacheValid: Compares current entity content hashes against cached hashes to detect changes
    computeEntityHash: Generates SHA256 hash of entity summary for change detection
    clearCache: Removes all cached trace links and content hashes
    getCacheStats: Returns statistics about cached trace links including count and file size


scenario: DiscoverEntitiesInCatalog
User queries "List all entities in NexusAssistant catalog"
@QueryProcessor parses intent and identifies catalog filter.
@QueryProcessor calls @KnowledgeGraph getEntities with catalog="NexusAssistant".
@KnowledgeGraph returns all entities from that catalog with roles and brief purposes.
@QueryProcessor formats results grouped by layer and returns as JSON.

scenario: FilterEntitiesBySemanticContext
User queries "Find entities related to parsing"
@QueryProcessor generates embedding for "parsing" using embeddingService.
@QueryProcessor performs semantic search across all entity embeddings in @KnowledgeGraph.
Entities like @NexusParser, @CodeParser, and @ValidationEngine match above semantic threshold.
@QueryProcessor returns matched entities with confidence scores and explains their parsing capabilities.

scenario: ExploreEntityWithRelationships
User queries "Show details for NexusParser entity"
@QueryProcessor calls @KnowledgeGraph getEntity("NexusParser").
@QueryProcessor retrieves entity definition with purpose, properties, and actions.
@QueryProcessor calls @KnowledgeGraph getRelations("NexusParser") to get all relationships.
Results include complete entity structure plus related entities like @ValidationEngine, @KnowledgeGraph, and @ParsedSpecification.
@QueryProcessor returns full entity context enabling deeper exploration.

scenario: BrowseEntitiesByLayer
User queries "Show all design layer entities"
@QueryProcessor identifies layer filter from query intent.
@QueryProcessor calls @KnowledgeGraph getEntities with layer="design".
@KnowledgeGraph returns entities from design catalogs (architecture files).
@QueryProcessor groups results by catalog and includes entity counts.
Results show complete design layer structure across all architectural specifications.

scenario: FilterEntitiesByRole
User queries "Find all components"
@QueryProcessor recognizes role filter in query.
@QueryProcessor calls @KnowledgeGraph filterEntitiesByRole("component").
@KnowledgeGraph returns entities where role="component" across all catalogs.
Results include @QueryProcessor, @MCPServer, @ValidationEngine, @CodeParser, @TraceabilityMatcher, @EmbeddingCache.
@QueryProcessor formats results showing how components interact in system architecture.

scenario: ExploreSystemOverview
User requests system overview without specific query
@QueryProcessor calls @KnowledgeGraph getCatalogs to list all catalogs.
@KnowledgeGraph returns catalog statistics with entity counts per layer.
@QueryProcessor identifies key entities in each catalog based on relation counts.
Results provide high-level map of system structure with entry points for further exploration.

scenario: AccurateContextualEntityRetrieval
User queries "What entities are involved in processing payment transactions?"
@QueryProcessor calls extractQueryConcepts to identify key terms: "payment", "transactions", "processing".
@QueryProcessor generates query embedding using embeddingService via @EmbeddingCache (cached if query seen before).
@QueryProcessor calls findRelevantEntities with exhaustiveSearch=true ensuring all entities are evaluated.
Searches pre-indexed vectorStore completely (populated by @TraceabilityMatcher) comparing query against all entity embeddings.
Computes cosine similarity for every entity to ensure no relevant matches are missed.
Applies semanticThreshold=0.6 to filter candidates, tuned to favor recall over premature filtering.
@QueryProcessor retrieves all matching entities from @KnowledgeGraph: PaymentFlow, PaymentGateway, PaymentService, TransactionValidator, plus edge cases.
@QueryProcessor calls rankByRelevance applying multi-factor scoring with accuracy-tuned weights.
Verifies each result meets minConfidenceScore=0.3 threshold ensuring quality.
Returns complete, accurate ranked results with confidence scores and relevance explanations (typical response time 200-500ms prioritizing correctness).

scenario: DeepSemanticUnderstanding
User asks "Which features help users recover from errors?"
@QueryProcessor generates embedding for query capturing semantic meaning of "error recovery".
@QueryProcessor searches vectorStore comparing query embedding against all entity embeddings.
@QueryProcessor identifies semantic matches beyond keyword matching:
    - Entities with "retry", "rollback", "validation" in actions match "recover from errors" semantically
    - Entities with "error handling", "resilience" in purposes match even without exact term "recover"
    - @ValidationEngine matches (0.73 similarity) due to error detection and reporting capabilities
@QueryProcessor retrieves full entity details from @KnowledgeGraph including purposes, properties, actions.
@QueryProcessor examines entity relationships to find connected error management entities.
Results include entities from multiple layers explaining complete error recovery ecosystem with semantic reasoning.

scenario: CompleteCrossLayerSearch
User queries "What defines and implements user authentication?"
@QueryProcessor recognizes cross-layer intent from query containing "defines" (product) and "implements" (design/code).
@QueryProcessor enables parallelSearchEnabled and launches concurrent exhaustive searches:
    - Thread 1: searches ALL product layer entities in vectorStore completely
    - Thread 2: searches ALL design layer entities in vectorStore completely
    - Thread 3: searches ALL implementation layer entities in vectorStore completely
All searches use same query embedding against layer-filtered vector stores with exhaustiveSearch=true.
Each thread computes similarity for every entity in its layer ensuring no relevant entities missed.
Product search finds all authentication features, design search finds all auth components including edge cases.
@QueryProcessor calls crossLayerSearch to retrieve ALL @TraceLink objects between matched entities.
@KnowledgeGraph provides complete trace connections showing product→design→code relationships.
@QueryProcessor unifies results showing Authentication feature traces to AuthService component traces to auth_handler.py code, plus related entities.
Returns complete cross-layer view with traceability (typical 200-600ms prioritizing completeness over speed).

scenario: IntelligentEntityRanking
@QueryProcessor receives multiple matching entities from semantic search with raw similarity scores.
@QueryProcessor applies rankByRelevance multi-factor algorithm:
    1. Semantic similarity score (weight 0.5): cosine similarity from vector search
    2. Entity richness (weight 0.2): count of properties + actions indicating detail level
    3. Relationship centrality (weight 0.2): in-degree + out-degree from @KnowledgeGraph relations
    4. Layer match (weight 0.1): bonus if entity layer matches query context
For each entity, @QueryProcessor computes weighted score and generates relevance explanation.
Example: PaymentGateway scores (0.82 * 0.5) + (12/20 * 0.2) + (8/15 * 0.2) + (1.0 * 0.1) = 0.64 total relevance.
@QueryProcessor sorts by composite score and formats results with per-entity explanations.
Results show most contextually relevant entities first with transparent scoring rationale.

scenario: AccurateIterativeRefinement
User performs sequence: "Find payment entities" → explores PaymentGateway → "Show related entities".
First query: @QueryProcessor generates embedding, exhaustively searches vectorStore ensuring all payment-related entities found.
Returns PaymentGateway and all related entities with accurate relevance scores (typical 200-400ms).
@QueryProcessor stores query context in queryContextCache including query embedding and selected entity for efficiency.
User explores PaymentGateway: @QueryProcessor retrieves complete entity details from @KnowledgeGraph with all properties, actions, and relationships.
Second query "Show related entities": @QueryProcessor detects context from queryContextCache (PaymentGateway).
@QueryProcessor calls @KnowledgeGraph getRelations("PaymentGateway") retrieving ALL connected entities without filtering.
@QueryProcessor enhances results using cached embeddings from first search to provide relevance scores, no redundant API calls.
Returns complete relationship graph ensuring user sees all relevant connections (typical 50-150ms due to context awareness).
@EmbeddingCache hit rate improves with repeated explorations enabling efficient iterative discovery without sacrificing completeness.

scenario: SpecificationUpdate
Developer modifies a .nxs file. 
@SpecificationStore detects the change and triggers @NexusParser to re-parse the file.
@KnowledgeGraph updates affected entities and relations to reflect the changes.

scenario: QueryingSpecifications
AI coding assistant queries @NexusAssistantService through @APIGateway.
@QueryProcessor searches @KnowledgeGraph for relevant entities and relationships, then returns results as structured JSON.

scenario: SystemInitialization
On startup, @SpecificationStore loads all .nxs files from configured directories.
@NexusParser parses each file in parallel. 
@KnowledgeGraph builds the complete entity relationship graph with three-layer model. 
@APIGateway and @MCPServer become ready to serve requests.

scenario: MCPAgentIntegration
External AI agent connects to @NexusAssistantService through @MCPServer using MCP protocol.
Agent discovers available tools exposed by @MCPServer.
Agent requests specification context via MCP tool call.
@MCPServer routes request to @QueryProcessor, which queries @KnowledgeGraph.
Results are formatted by @MCPServer as MCP response and returned to agent.

scenario: CodeRepositoryIndexing
Developer configures code repository path in @NexusAssistantService.
@CodeParser scans repository and parses source files using language-specific AST parser.
For each file, @CodeParser extracts classes and functions into @CodeEntity objects.
@CodeParser enriches entities with parent context and filters out trivial/private functions.
@ParsedCodeRepository is created with all @CodeEntity objects and stored in @KnowledgeGraph.

scenario: EnrichedEmbeddingGeneration
@TraceabilityMatcher begins indexing a specification entity from design layer.
@TraceabilityMatcher calls @ContextEnricher enrichSpecEntity with entity, catalog, layer, and @KnowledgeGraph.
@ContextEnricher calls @LayerSemantics getLayerDescription("design") receiving: "Describes HOW the system is organized, technical architecture, services, components".
@ContextEnricher calls @KnowledgeGraph getRelations for entity retrieving all connected entities with relationship types.
@ContextEnricher identifies 3 related entities: dependencies on 2 other services and composition of 1 data structure.
@ContextEnricher formats enriched summary including: layer semantics explanation, complete entity purpose, all properties with descriptions, all actions with descriptions, related entities with relationship context, architectural role in system.
@TraceabilityMatcher receives enriched summary from @ContextEnricher (significantly richer than simple entity text).
@TraceabilityMatcher generates embedding for enriched summary capturing full architectural context.
Embedding now encodes: what layer means, entity's complete semantics, relationships to other entities, architectural role.
When compared to code entity embeddings, similarity matching captures semantic connections that simple descriptions miss.

scenario: LLMEnhancedTraceabilityDiscovery
After specifications and code are loaded into @KnowledgeGraph, @TraceabilityMatcher begins hybrid discovery process.
For each specification entity in each layer, @TraceabilityMatcher uses @ContextEnricher to create enriched summary then generates embedding using OpenAI API.
@EmbeddingCache checks if embedding already exists for this content hash, returns cached or generates new.
For each @CodeEntity, @TraceabilityMatcher uses @ContextEnricher to create enriched code summary then generates embedding.
@SemanticMatcher performs cosine similarity search following valid layer transitions to generate candidates:
    - Product layer entities compared to design layer entities (always)
    - Design layer entities compared to both implementation layer entities AND code entities (alternative paths)
    - Implementation layer entities compared to code entities (when implementation specs exist)
Candidates above embeddingSimilarityThreshold (default 0.6) are passed to @LLMReasoner for validation.
@LLMReasoner analyzes each candidate by reading full specification purposes, properties, actions, and code context.
@LLMReasoner validates if semantic connection is logically sound or discovers why embeddings found false positive.
@LLMReasoner identifies additional connections through multi-hop reasoning that embeddings missed.
@ExplanationGenerator creates human-readable rationale for each validated trace explaining the connection.
@TraceValidator computes composite confidence score (0.4 * embedding_similarity + 0.6 * llm_confidence).
When composite confidence exceeds threshold (default 0.7), @TraceLink is created with validation status and explanation.
All @TraceLink objects stored in @KnowledgeGraph with confidence scores, rationales, and validation status.
@QueryProcessor can traverse @TraceLink objects to trace across layers with explainable connections users can trust.

scenario: DisambiguatingMultipleCandidates
@TraceabilityMatcher discovers three design entities with similar embeddings (0.72, 0.71, 0.70) to PaymentService code.
@SemanticMatcher generates all three as candidates: PaymentGateway, PaymentProcessor, PaymentValidator.
@LLMReasoner receives candidates with full specification contexts and PaymentService code.
@LLMReasoner analyzes PaymentService code behavior: processes transactions, validates cards, handles errors.
@LLMReasoner examines each specification's purpose and actions for logical match.
@LLMReasoner determines PaymentGateway (external integration focus) best matches code's transaction processing.
@LLMReasoner rejects PaymentProcessor (internal logic orchestration) and PaymentValidator (validation only).
@ExplanationGenerator creates rationale: "PaymentService implements PaymentGateway because code handles external API calls, matches gateway's process action, and manages transaction lifecycle as specified."
@TraceValidator computes high LLM confidence (0.85) despite similar embedding scores.
@TraceLink created for PaymentGateway→PaymentService with composite confidence 0.79 and clear explanation.
False positives prevented - developers see correct, explainable trace link.

scenario: DiscoveringIndirectLinks
Product requirement UserAuthentication doesn't mention specific implementation details.
@SemanticMatcher finds low embedding similarity (0.58) to auth_handler.py code, below candidate threshold.
@LLMReasoner examines UserAuthentication relationships in @KnowledgeGraph.
@LLMReasoner finds UserAuthentication traces to AuthService design entity (high confidence).
@LLMReasoner analyzes AuthService specification and finds strong semantic match to auth_handler.py.
@LLMReasoner reasons through chain: UserAuthentication→AuthService→auth_handler.py.
@TraceabilityMatcher creates multi-hop @TraceLink path with explanations at each step.
@ExplanationGenerator describes full chain rationale showing how product requirement flows through design to code.
Developer queries UserAuthentication and sees complete implementation path despite no direct similarity.
Multi-hop reasoning reveals connections pure embedding search cannot find.

scenario: ExplainingTraceRationale
Developer views trace link from PaymentFlow specification to payment_processor.py code.
Developer requests explanation for why this connection exists.
@QueryProcessor retrieves @TraceLink from @KnowledgeGraph including stored rationale.
Rationale generated by @ExplanationGenerator during discovery explains:
    "payment_processor.py implements PaymentFlow specification because:
    1. Code's process_payment function fulfills PaymentFlow's processTransaction action
    2. Error handling in code matches PaymentFlow's recovery requirements
    3. Code validates payment methods as specified in PaymentFlow properties
    4. Transaction state management aligns with PaymentFlow's flow semantics
    Confidence: 0.83 (embedding: 0.74, LLM validation: 0.89)"
Developer understands traceability rationale and trusts the connection.
Explanation enables informed decisions about code changes and their impact on requirements.

scenario: LearningFromFeedback
Developer reviews discovered trace links and validates 20 connections.
Developer confirms 15 as correct, rejects 3 as false positives, marks 2 as uncertain.
For each decision, developer provides context through @FeedbackLearner interface.
@FeedbackLearner stores validated traces with full context in feedbackStore.
@FeedbackLearner analyzes rejected traces to identify common patterns leading to false positives.
@FeedbackLearner adjusts embeddingSimilarityThreshold from 0.6 to 0.65 for this project.
@FeedbackLearner updates LLM validation prompts to emphasize patterns from correct traces.
Next discovery iteration shows improved precision: fewer false positives, maintained recall.
@TraceabilityMatcher continuously improves without manual retraining or threshold tuning.
System adapts to project-specific patterns and terminology over time.

scenario: ForwardTracing
Developer queries "what code implements PaymentGateway specification?"
@QueryProcessor identifies PaymentGateway entity in @KnowledgeGraph design layer.
@QueryProcessor calls getTraceLinks with forward direction to find code implementations.
@KnowledgeGraph returns @TraceLink objects pointing to @CodeEntity objects with confidence scores and explanations.
@QueryProcessor retrieves full @CodeEntity details including file paths and line numbers.
Results returned as JSON showing matched code with confidence scores, validation status, and human-readable rationales.

scenario: BackwardTracing
Developer views payment_service.py file and queries "why does this code exist?"
@QueryProcessor extracts @CodeEntity objects for functions in that file from @KnowledgeGraph.
@QueryProcessor calls getTraceLinks with backward direction starting from code layer.
@KnowledgeGraph returns @TraceLink objects from code to implementation layer specifications.
@QueryProcessor follows next @TraceLink objects from implementation to design layer.
@QueryProcessor follows final @TraceLink objects from design to product layer.
Results show complete chain: code ← implementation spec ← design spec ← product requirement.
Each link includes confidence score and rationale explaining the connection.
Developer sees full business justification and architectural reasoning for the code.

scenario: FullChainTracingWithImplementation
Product manager defines PaymentFlow requirement in product layer.
Developer queries "how is PaymentFlow implemented?"
@QueryProcessor finds PaymentFlow entity in product layer of @KnowledgeGraph.
@QueryProcessor traverses @TraceLink from product to design layer, finds PaymentGateway entity.
@QueryProcessor traverses @TraceLink from design to implementation layer, finds PaymentService component spec.
@QueryProcessor traverses @TraceLink from implementation to code, finds payment.gateway.PaymentService.process_payment function.
Results show complete forward chain: product requirement → design architecture → implementation spec → actual code.
Each hop includes the traced entity, confidence score, and rationale for connection.

scenario: DirectDesignToCodeTracing
Product manager defines SearchFeature requirement in product layer.
Developer queries "how is SearchFeature implemented?"
@QueryProcessor finds SearchFeature entity in product layer of @KnowledgeGraph.
@QueryProcessor traverses @TraceLink from product to design layer, finds SearchAPI entity.
@QueryProcessor checks for implementation layer links but finds none (design is detailed enough).
@QueryProcessor traverses @TraceLink directly from design to code, finds search.api.SearchService.search function.
Results show shorter chain: product requirement → design architecture → actual code (skipping implementation layer).
This path is used when design specifications are detailed enough and no separate implementation spec exists.

scenario: CodeChangeReindexing
Developer modifies payment_service.py file, @SpecificationStore detects change.
@CodeParser re-parses the modified file into new @CodeEntity objects.
@KnowledgeGraph removes old code entities from that file using removeCodeEntitiesFromFile.
@EmbeddingCache checks content hashes - unchanged functions keep cached embeddings.
@TraceabilityMatcher regenerates embeddings only for modified functions using @EmbeddingCache.
@TraceabilityMatcher recomputes @TraceLink objects for changed entities and updates @KnowledgeGraph.
Queries immediately reflect updated traceability without full system reindex.

scenario: SemanticNaturalLanguageQuery
User submits natural language query "What components are responsible for parsing specifications?"
@QueryProcessor receives query and checks semanticSearchEnabled property.
@QueryProcessor generates embedding for the query using embeddingService (OpenAI API).
@EmbeddingCache checks if this exact query was cached, returns cached embedding or generates new.
@QueryProcessor retrieves all entity embeddings from @KnowledgeGraph (previously indexed by @TraceabilityMatcher).
@QueryProcessor computes cosine similarity between query embedding and each entity embedding.
Entities with similarity above semanticThreshold (default 0.6) are collected.
@QueryProcessor ranks results by similarity score descending.
Results include @NexusParser, @ValidationEngine, @CodeParser with confidence scores.
@QueryProcessor returns top maxResults (default 10) as JSON with entity details and relevance scores.

scenario: IntentBasedLayerFiltering
User queries "Find all entities in the design layer"
@QueryProcessor calls matchQueryIntent to parse query structure.
matchQueryIntent identifies keywords "all entities" and "design layer" indicating browse intent with layer filter.
@QueryProcessor recognizes this as structured query, not requiring semantic search.
@QueryProcessor calls @KnowledgeGraph getEntities with layer filter "design".
All 19 design layer entities returned directly without embedding computation.
Results formatted with entity roles, purposes, and action counts.

scenario: FuzzyConceptMatching
User asks "What handles file watching?" without knowing exact entity name.
@QueryProcessor generates embedding for "file watching" concept using embeddingService.
Query embedding compared against all entity embeddings in @KnowledgeGraph.
@SpecificationStore entity has high semantic similarity due to watchForChanges property and monitoring purpose.
Match exceeds semanticThreshold (0.6), ranked highest due to "watches for file changes" in purpose statement.
@QueryProcessor returns @SpecificationStore with confidence 0.78 showing relevant properties and watchFile action.

scenario: SharedEmbeddingInfrastructure
@QueryProcessor and @TraceabilityMatcher both initialize with same embeddingService (OpenAI API).
Both components share single @EmbeddingCache instance configured in @NexusAssistantService.
@TraceabilityMatcher indexes all specification entities during TraceabilityDiscovery scenario.
Entity embeddings stored in cache with content hashes as keys.
When @QueryProcessor performs semantic search, it reuses entity embeddings created by @TraceabilityMatcher.
No duplicate embedding generation for specification entities - cache provides efficiency.
Only query embeddings are newly generated per search request.

rule: FunctionLevelGranularity
@CodeParser must extract individual functions and methods as separate @CodeEntity objects for precise traceability between specification actions and code implementations

rule: ContentBasedCaching
@EmbeddingCache uses SHA256 hash of entity content as cache key, enabling efficient reindex when only some functions change in a file

rule: FullFileReindexStrategy
When code file changes, @CodeParser re-parses entire file rather than attempting incremental AST diff - simpler and more reliable with @EmbeddingCache optimization

rule: SemanticSimilarityThreshold
@TraceabilityMatcher only creates @TraceLink when cosine similarity exceeds configured threshold (default 0.7), avoiding spurious low-confidence connections

rule: ContextEnrichment
@CodeParser must include parent class and module information in @CodeEntity to improve semantic matching accuracy for functions with generic names

rule: LayeredTraceability
@TraceLink objects follow valid layer transitions in the traceability chain: product→design (required), design→implementation (optional), design→code (alternative when no implementation spec), implementation→code (when implementation exists) - product cannot link directly to implementation or code, bypassing design layer

rule: FlexibleDesignLinks
Design specifications can trace to either implementation layer or directly to code - @TraceabilityMatcher compares design entities against both implementation entities and code entities, creating links to whichever has higher semantic similarity

rule: EmbeddingModelConsistency
All embeddings must use same model (text-embedding-3-small) and dimensions (1536) to ensure vector comparisons are valid across specification and code entities

rule: ValidLayerTransitions
@TraceabilityMatcher only creates @TraceLink objects for valid layer transitions: product→design, design→implementation, design→code, implementation→code - filters vector store by these rules to prevent invalid transitions like product→code or implementation→design

rule: SemanticSearchThreshold
@QueryProcessor uses lower similarity threshold (default 0.6) for natural language queries compared to @TraceabilityMatcher (0.7), allowing broader conceptual matches for exploratory search while traceability requires higher confidence

rule: QueryEmbeddingCaching
@QueryProcessor reuses @EmbeddingCache for both query embeddings and entity embeddings - entity embeddings indexed once by @TraceabilityMatcher, query embeddings cached per unique query text to avoid redundant API calls for repeated questions

rule: SharedEmbeddingService
@QueryProcessor and @TraceabilityMatcher must share same embeddingService configuration (OpenAI text-embedding-3-small, 1536 dimensions) and @EmbeddingCache instance to ensure vector compatibility and maximize cache efficiency

rule: EntityDiscoverability
@KnowledgeGraph must support entity filtering by catalog, layer, and role, and @QueryProcessor must enable users to discover entities through browsing, semantic search, and structured queries without requiring prior knowledge of entity names

rule: AccuracyFirst
@QueryProcessor must prioritize accuracy and completeness of results over response speed - returning all relevant entities with high precision is more important than fast responses, though reasonable performance (sub-second response times) should be maintained through caching and indexing optimizations

rule: OptimizedSemanticRetrieval
@QueryProcessor should optimize response times by using pre-indexed embeddings from @TraceabilityMatcher, efficient vector similarity search, and caching through @EmbeddingCache - but performance optimizations must never skip entities or compromise result quality

rule: DeepEntityUnderstanding
@TraceabilityMatcher must index complete entity semantics including purpose statements, property descriptions, and action definitions when generating embeddings - @QueryProcessor must match queries against this rich semantic representation, not just entity names or simple keywords

rule: MultiFactorRanking
@QueryProcessor must rank results using composite scoring algorithm with configurable weights: semantic similarity (default 0.5), entity richness measured by properties+actions count (default 0.2), relationship centrality from graph degree (default 0.2), and layer appropriateness (default 0.1) - each result must include relevance explanation

rule: CrossLayerCompleteness
@QueryProcessor must support parallel search across product, design, implementation, and code layers when parallelSearchEnabled is true, using layer-filtered vector stores and unifying results with @TraceLink connections - parallel execution must ensure all layers are searched completely without missing entities

rule: ContextualCaching
@QueryProcessor should maintain queryContextCache for recent searches and explorations to improve response times for iterative refinement without compromising accuracy - cache includes query embeddings, selected entities, and relationship graphs eliminating redundant computations

rule: VectorStoreOptimization
@QueryProcessor must reuse vectorStore populated by @TraceabilityMatcher during entity indexing - no separate embedding generation for search, all entity embeddings pre-computed and cached enabling efficient similarity computations

rule: ExhaustiveSearchDefault
@QueryProcessor must default to exhaustiveSearch=true ensuring all entities are evaluated during semantic search - early termination optimizations should only be enabled when explicitly configured and must not compromise result completeness

rule: ThresholdTuning
Similarity thresholds must be tuned to favor recall (finding all relevant entities) while maintaining acceptable precision - missing relevant entities is more harmful than including some less relevant ones that can be filtered through ranking

rule: HybridTraceDiscovery
@TraceabilityMatcher must combine embedding-based similarity with LLM reasoning - embeddings generate candidates quickly, LLM validates and enriches with contextual understanding - neither approach alone is sufficient for accurate, trustworthy traceability

rule: ExplainableTraceLinks
Every @TraceLink must include human-readable rationale generated by @ExplanationGenerator explaining why the connection exists, which specification requirements the code fulfills, and how behaviors align - developers must understand traceability logic, not just see connections

rule: ConfidenceTransparency
@TraceLink objects must expose both embedding similarity and LLM confidence scores separately, plus composite confidence - users see how each component contributed to the decision enabling informed trust and focused review of uncertain traces

rule: LLMValidationRequired
All candidate trace links above embedding similarity threshold must be validated by @LLMReasoner before acceptance - LLM analyzes full entity context including purposes, properties, actions, code behavior, and relationships to confirm logical soundness and filter false positives

rule: MultiHopReasoning
@LLMReasoner must be capable of following relationship chains in @KnowledgeGraph to discover indirect trace links across multiple hops - enables tracing product→design→implementation→code even when direct similarity between product and code is low

rule: AmbiguityResolution
When @SemanticMatcher generates multiple candidates with similar embedding scores, @LLMReasoner must analyze full context to disambiguate and select correct connection - prevents false trace links from misleading developers about implementation relationships

rule: ContinuousLearning
@FeedbackLearner must record all user validation decisions and adapt @TraceabilityMatcher behavior without manual retraining - adjusts thresholds, refines LLM prompts, and learns project-specific patterns to continuously improve trace quality over time

rule: CompositeConfidenceScoring
@TraceValidator must combine embedding similarity (default weight 0.4) and LLM validation confidence (default weight 0.6) into composite score - LLM reasoning weighted higher because it validates logical correctness while embeddings only measure semantic similarity

rule: ValidationStatusTracking
@TraceLink objects must include validationStatus field indicating whether link is validated (LLM confirmed), candidate (embedding-based only), or rejected (LLM invalidated) - enables different treatment and visualization of trace link confidence levels
