catalog: NexusAssistantArchitecture

entity: NexusAssistantService
role: platform
purpose:
    - Single deployable service providing specification parsing and querying
    - Contains parser, validation engine, specification store, knowledge graph, query processor, API gateway, MCP server, code parser, and traceability matcher
    - Includes LLM-powered traceability components: semantic matcher, LLM reasoner, trace validator, explanation generator, trace storage
    - Exposes REST API via gateway and MCP protocol via server
    - Discovers implicit traceability between specifications and source code using hybrid embeddings + LLM reasoning
    - Persists trace links to disk avoiding expensive LLM validation on every restart
properties:
    deploymentModel: CloudService
    runtimeEnvironment: Python
rules:
    FunctionLevelGranularity: CodeParser must extract individual functions and methods as separate CodeEntity objects for precise traceability between specification actions and code implementations
    ContentBasedCaching: EmbeddingCache uses SHA256 hash of entity content as cache key, enabling efficient reindex when only some functions change in a file
    FullFileReindexStrategy: When code file changes, CodeParser re-parses entire file rather than attempting incremental AST diff - simpler and more reliable with EmbeddingCache optimization
    SemanticSimilarityThreshold: TraceabilityMatcher only creates TraceLink when cosine similarity exceeds configured threshold (default 0.7), avoiding spurious low-confidence connections
    ContextEnrichment: CodeParser must include parent class and module information in CodeEntity to improve semantic matching accuracy for functions with generic names
    LayeredTraceability: TraceLink objects follow valid layer transitions in the traceability chain: product→design (required), design→implementation (optional), design→code (alternative when no implementation spec), implementation→code (when implementation exists) - product cannot link directly to implementation or code, bypassing design layer
    FlexibleDesignLinks: Design specifications can trace to either implementation layer or directly to code - TraceabilityMatcher compares design entities against both implementation entities and code entities, creating links to whichever has higher semantic similarity
    EmbeddingModelConsistency: All embeddings must use same model (text-embedding-3-small) and dimensions (1536) to ensure vector comparisons are valid across specification and code entities
    ValidLayerTransitions: TraceabilityMatcher only creates TraceLink objects for valid layer transitions: product→design, design→implementation, design→code, implementation→code - filters vector store by these rules to prevent invalid transitions like product→code or implementation→design
    SemanticSearchThreshold: QueryProcessor uses lower similarity threshold (default 0.6) for natural language queries compared to TraceabilityMatcher (0.7), allowing broader conceptual matches for exploratory search while traceability requires higher confidence
    QueryEmbeddingCaching: QueryProcessor reuses EmbeddingCache for both query embeddings and entity embeddings - entity embeddings indexed once by TraceabilityMatcher, query embeddings cached per unique query text to avoid redundant API calls for repeated questions
    SharedEmbeddingService: QueryProcessor and TraceabilityMatcher must share same embeddingService configuration (OpenAI text-embedding-3-small, 1536 dimensions) and EmbeddingCache instance to ensure vector compatibility and maximize cache efficiency
    EntityDiscoverability: KnowledgeGraph must support entity filtering by catalog, layer, and role, and QueryProcessor must enable users to discover entities through browsing, semantic search, and structured queries without requiring prior knowledge of entity names
    AccuracyFirst: QueryProcessor must prioritize accuracy and completeness of results over response speed - returning all relevant entities with high precision is more important than fast responses, though reasonable performance (sub-second response times) should be maintained through caching and indexing optimizations
    OptimizedSemanticRetrieval: QueryProcessor should optimize response times by using pre-indexed embeddings from TraceabilityMatcher, efficient vector similarity search, and caching through EmbeddingCache - but performance optimizations must never skip entities or compromise result quality
    DeepFragmentUnderstanding: TraceabilityMatcher must index fragments at statement level including each purpose statement, property description, action definition, rule statement, and scenario step with parent entity and referenced entity context - QueryProcessor must match queries against fragment embeddings returning precise statement-level matches with complete entity context
    SimilarityRanking: QueryProcessor must rank semantic search results by cosine similarity score descending - fragments with higher similarity to any query candidate are ranked higher, with deduplication keeping maximum similarity per fragment
    CrossLayerSearch: QueryProcessor enables cross-layer search by calling semanticSearch multiple times with different layer filters - each search is independent and searches all fragments in that layer using query candidate expansion and similarity matching
    EmbeddingCaching: QueryProcessor uses shared EmbeddingCache for query candidate embeddings and fragment embeddings - cache stores embeddings by content hash enabling reuse across queries and avoiding redundant API calls for repeated query phrases
    FragmentEmbeddingReuse: QueryProcessor must load fragmentEmbeddings from TraceabilityMatcher after indexing - no separate embedding generation for search, all fragment embeddings pre-computed and cached enabling efficient similarity computations during semantic search
    ComprehensiveFragmentSearch: QueryProcessor semanticSearch must search all fragment embeddings comparing each query candidate against all fragments to ensure no relevant matches are missed - deduplication keeps highest similarity per fragment across all candidates
    ThresholdTuning: Similarity thresholds must be tuned to favor recall (finding all relevant entities) while maintaining acceptable precision - missing relevant entities is more harmful than including some less relevant ones that can be filtered through ranking
    HybridTraceDiscovery: TraceabilityMatcher must combine embedding-based similarity with LLM reasoning - embeddings generate candidates quickly, LLM validates and enriches with contextual understanding - neither approach alone is sufficient for accurate, trustworthy traceability
    ExplainableTraceLinks: Every TraceLink must include human-readable rationale generated by ExplanationGenerator explaining why the connection exists, which specification requirements the code fulfills, and how behaviors align - developers must understand traceability logic, not just see connections
    ConfidenceTransparency: TraceLink objects must expose both embedding similarity and LLM confidence scores separately, plus composite confidence - users see how each component contributed to the decision enabling informed trust and focused review of uncertain traces
    LLMValidationRequired: All candidate trace links above embedding similarity threshold must be validated by LLMReasoner before acceptance - LLM analyzes full entity context including purposes, properties, actions, code behavior, and relationships to confirm logical soundness and filter false positives
    MultiHopReasoning: LLMReasoner must be capable of following relationship chains in KnowledgeGraph to discover indirect trace links across multiple hops - enables tracing product→design→implementation→code even when direct similarity between product and code is low
    AmbiguityResolution: When SemanticMatcher generates multiple candidates with similar embedding scores, LLMReasoner must analyze full context to disambiguate and select correct connection - prevents false trace links from misleading developers about implementation relationships
    CompositeConfidenceScoring: TraceValidator must combine embedding similarity (default weight 0.4) and LLM validation confidence (default weight 0.6) into composite score - LLM reasoning weighted higher because it validates logical correctness while embeddings only measure semantic similarity
    ValidationStatusTracking: TraceLink objects must include validationStatus field indicating whether link is validated (LLM confirmed), candidate (embedding-based only), or rejected (LLM invalidated) - enables different treatment and visualization of trace link confidence levels
    RelationReference: Each Relation that is derived from EntityDefinition explicit relations section must contain source entity as first element and target entity as second element
    

entity: ParsedSpecification
role: struct
purpose:
    - Structured representation of a parsed Nexus specification file
    - Output from NexusParser containing all elements of a .nxs file
properties:
    catalogName: String, name declared in catalog statement
    filePath: String, source file path
    imports: collection of ImportItem, imported module declarations
    entities: collection of EntityDefinition, parsed entity definitions
    scenarios: collection of NamedBlock, scenarios with type scenario
    parseTimestamp: Number, when file was parsed in unix timestamp
    specificationHash: String, content hash for change detection

entity: EntityDefinition
role: struct
purpose:
    - Represents a parsed entity from Nexus specification
    - Contains all entity metadata including role, purpose, properties, actions, relations, and rules
properties:
    entityName: String, entity identifier
    catalog: String, the catalog to which the entity belongs
    role: String, entity role (platform, module, component, service, actor, struct, etc)
    purposes: collection of NamedBlock, entity purposes with type purpose
    properties: collection of NamedBlock, entity properties with type property
    actions: collection of NamedBlock, entity actions with type action
    relations: collection of NamedBlock, explicit entity relations with type explicit
    rules: collection of NamedBlock, entity rules with type rule

entity: ImportItem
role: struct
purpose:
    - Represents an import declaration from a Nexus specification file
    - Contains module path and optional alias
properties:
    modulePath: String, the qualified module path being imported
    alias: String, optional alias name for the imported module

entity: Statement
role: struct
purpose:
    - Atomic unit of text that may reference entities (only in relations and scenarios)
properties:
    text: String, the actual text content
    references: collection of String, referenced entity names (only populated for relations and scenarios)

entity: NamedBlock
role: struct
purpose:
    - Named container for one or more statements
    - Used for purposes, properties, actions, rules, scenarios, and explicit relations
properties:
    name: String, identifier for the block (for explicit relations, this is the target entity name)
    relationType: one of {purpose, property, action, rule, scenario, explicit}, what kind of block this is
    statements: collection of Statement, the content

entity: Relation
role: struct
purpose:
    - Represents a typed relationship between entities in KnowledgeGraph
    - Explicit relations are directional: source entity -> target entity
    - Derived from explicit relations section and scenario references
properties:
    entities: collection of String, entity names participating in this relation (for explicit relations, first is source, second is target)
    relationType: one of {purpose, property, action, rule, scenario, explicit}, how the entities are related
    statement: Statement, the statement that created this relation

entity: Fragment
role: struct
purpose:
    - Represents atomic piece of specification or code content for fine-grained semantic search
    - Enables precise statement-level matching rather than coarse entity-level matching
    - Each fragment has unique identifier, content text, parent entity, and referenced entities
    - Fragments are indexed and embedded separately for accurate semantic search
properties:
    fragmentId: String, unique identifier (e.g., "catalog.Entity.purpose.0.1" or "code.function.signature")
    fragmentType: one of {role, purpose, property, action, rule, scenario, code_docstring, code_signature, code_body}, type of fragment
    content: String, actual text to embed and search
    parentEntity: String, qualified name of parent entity providing context
    referencedEntities: collection of String, entity names mentioned in this fragment
    layer: String, layer this fragment belongs to (product, design, implementation, code)
    catalog: String, catalog name
    metadata: struct, additional information like block_name, line_range, entity_type for code fragments 

entity: NexusParser
role: component
purpose:
    - Parses Nexus language files (.nxs) into ParsedSpecification structures
    - Uses validation engine to ensure syntax and semantic correctness
    - Populates knowledge graph with parsed entities, relations, rules, and scenarios
properties:
    parserLibrary: Lark, Python parsing library for grammar-based parsing
actions:
    parseFile: Reads and parses a .nxs file into ParsedSpecification
    validateSyntax: Checks for syntax errors and returns validation results
relations:
    @ParsedSpecification: produces parsed specification structures from .nxs files
    @ValidationEngine: sends parsed specifications to engine for syntax and semantic validation
    @KnowledgeGraph: populates graph with parsed entities and relations

entity: KnowledgeGraph
role: module
purpose:
    - Central repository maintaining in-memory graph of all parsed specification elements
    - Stores entities and typed relations between them (purpose, property, action, rule, scenario, explicit)
    - Stores fine-grained fragments for each statement, action, property, role with embeddings for precise semantic search
    - Maintains three-layer model: product views, system design views, and component implementations
    - Stores code entities and trace links for code traceability
    - Provides millisecond-speed lookups and traversals across specifications and code using optimized in-memory indexes
    - Enables rapid entity discovery through efficient filtering by catalog, layer, and role
    - Enables precise fragment-based search returning exact matching statements with full entity context
properties:
    indexingStrategy: InMemory
    enableCrossFileLinks: Boolean, whether to link entities across different specification files, default true
    threeLayerModel: Boolean, maintains ProductView, SystemDesignView, and ComponentImplementation separation, default true
actions:
    addEntity: Inserts entity node with its properties and actions into graph
    addFragment: Stores Fragment with unique fragment_id and updates fragment index
    addRelation: Creates typed edge between entity nodes with relation type (purpose, property, action, rule, scenario, explicit)
    addCodeEntity: Inserts CodeEntity from parsed source code
    add_trace_link: Stores TraceLink discovered by traceability matcher
    getEntity: Returns entity by name
    getFragment: Returns Fragment by fragment_id
    getFragmentsByEntity: Returns all Fragment objects belonging to specific entity
    getAllFragments: Returns all fragments optionally filtered by layer and fragment type
    getCodeEntity: Returns CodeEntity by qualified name
    getRelations: Returns all relations for an entity, optionally filtered by relation type
    getTraceLinks: Returns TraceLink objects for an entity (forward to next layer or backward to previous layer)
    traceChain: Follows multiple TraceLink objects across layers to trace from any layer to any other layer
    findPath: Discovers paths between two entities through design layer
    getEntities: Returns all entities, optionally filtered by catalog, layer, or role
    getAllRelations: Returns all relations
    getCatalogs: Returns list of all catalogs with entity counts and layer information
    filterEntitiesByRole: Returns entities matching specific role (actor, service, component, etc)
    removeFragmentsByFile: Removes all fragments from entities in specific file (for reindexing)
    remove_code_entities_by_file: Removes all code entities from a specific file (for reindexing)
relations:
    @Relation: stores typed relation objects in graph
    @Fragment: stores fine-grained fragment objects in graph
    @CodeEntity: stores parsed code entity objects in graph
    @TraceLink: stores discovered trace link objects in graph

entity: QueryProcessor
role: component
purpose:
    - Direct query interface to knowledge graph without intent parsing
    - Searches knowledge graph for relevant fragments using semantic search with LLM-generated query candidates
    - Returns precise matching fragments with complete parent entity context and referenced entities
    - Handles traceability queries across specifications and code using trace links
    - Supports natural language queries through fragment-based embedding semantic matching with query expansion
    - Enables entity discovery and exploration through filtering and browsing
    - Returns query results as JSON with fragment details and entity context
    - Optimizes for speed through embedding caching while maintaining result quality
properties:
    semanticThreshold: Number, minimum cosine similarity for semantic query matches, default 0.6
    llmModel: String, model for query expansion using chat completions, default gpt-4o-mini
actions:
    semanticSearch: Generates multiple query candidate embeddings using LLM query expansion, searches fragments with each candidate, deduplicates by keeping highest similarity per fragment, returns enriched results with parent entity and referenced entities data
    traceToCode: Traces from specification entity to code implementations following trace link objects, returns trace paths with confidence scores and rationales
    traceToSpec: Traces from code back to specification entities following trace link objects backward, returns trace chains to product requirements
    getTraceLinks: Retrieves TraceLink objects with optional filters for entity name, source layer, and target layer
    assessCoverage: Checks which specification entities have code implementations, reports implemented entities and gaps
    discoverEntities: Lists entities from knowledge graph filtered by catalog, layer, role, or semantic context using semantic search
    exploreEntity: Retrieves detailed entity information including purpose, properties, actions, relationships, and trace links from knowledge graph
    browseEntityGraph: Navigates entity relationships enabling exploration of system structure and dependencies up to specified depth
    loadEmbeddings: Loads pre-generated fragment embeddings from traceability matcher vector store for semantic search
    updateFragmentEmbedding: Incrementally updates single fragment embedding during discovery enabling real-time semantic search availability
relations:
    @KnowledgeGraph: queries graph for entities, fragments, and relationships
    @EmbeddingCache: stores and retrieves query and fragment embeddings from cache
    @TraceabilityMatcher: loads pre-generated fragment embeddings from matcher
    @TraceLink: retrieves and traverses trace links for traceability queries

entity: SpecificationStore
role: platform
purpose:
    - Reads Nexus specification files from filesystem
    - Watches for file changes and triggers parser to re-parse modified files
properties:
    storageType: FileSystem
    watchForChanges: Boolean, default true
actions:
    loadSpecification: Reads specification from filesystem
    watchFile: Monitors file for changes
    listSpecifications: Returns all available specifications
relations:
    @NexusParser: triggers parser to re-parse modified specification files

entity: APIGateway
role: component
purpose:
    - Exposes REST API for external integrations
    - Routes requests to query processor
properties:
    authenticationRequired: Boolean, default false
actions:
    handleRequest: Processes incoming API request
    routeToService: Forwards to query processor
    formatResponse: Standardizes JSON responses
relations:
    @QueryProcessor: routes API requests to query processor for execution

entity: MCPServer
role: component
purpose:
    - Implements Model Context Protocol server for AI agent integration
    - Exposes query processor capabilities through MCP protocol including entity discovery and exploration
    - Enables both internal and external AI agents to query specifications and discover system structure
properties:
    protocolVersion: String, MCP protocol version supported, default 1.0
    transportType: one of {stdio, http}, communication transport mechanism, default stdio
    toolsEnabled: Boolean, whether to expose MCP tools, default true
actions:
    handleMCPRequest: Processes incoming MCP protocol request
    exposeTool: Registers query processor operations as MCP tools including discoverEntities, exploreEntity, and browseEntityGraph
    formatMCPResponse: Serializes results in MCP protocol format
relations:
    @QueryProcessor: exposes query processor capabilities to external agents through MCP protocol

entity: ValidationEngine
role: component
purpose:
    - Validates specifications against Nexus language rules
    - Ensures referenced entities exist
    - Checks relation cardinality constraints
properties:
    strictMode: Boolean, enforce all rules strictly, default true
actions:
    validateEntity: Checks entity definition correctness
    validateReferences: Ensures all referenced entities exist
    validateRelations: Verifies relation constraints are met
    reportViolations: Returns collection of validation errors

entity: CodeEntity
role: struct
purpose:
    - Structured representation of a parsed code element (file, class, function, or module)
    - Extracted from source code using AST parsing
    - Contains semantic information for embedding generation
properties:
    entityType: one of {file, class, function, module}, type of code element
    qualifiedName: String, fully qualified identifier (e.g., "payment.gateway.PaymentService.process_payment")
    filePath: String, absolute path to source file
    startLine: Number, beginning line number in file
    endLine: Number, ending line number in file
    sourceCode: String, actual implementation code
    docstring: String, extracted documentation or comments, may be empty
    language: String, programming language (python, typescript, etc)
    parentContext: String, parent class or module name for context
    signature: String, function/method signature including parameters

entity: ParsedCodeRepository
role: struct
purpose:
    - Collection of CodeEntity objects representing parsed source code repository
    - Output from code parser after scanning codebase
    - Stored in knowledge graph alongside specification entities
properties:
    repositoryPath: String, root directory of code repository
    language: String, primary programming language
    fileIndex: collection of String, paths of files that were parsed
    parseTimestamp: Number, when repository was last parsed
    contentHash: String, hash of repository state for change detection
relations:
    @CodeEntity: contains collection of code entities parsed from repository

entity: CodeParser
role: component
purpose:
    - Parses source code files into CodeEntity structures using language-specific AST parsers
    - Extracts classes, functions, and modules at appropriate granularity
    - Enriches entities with contextual information for better semantic matching
    - Filters out trivial or private elements that shouldn't be traced
properties:
    language: String, target programming language
    astParser: component, language-specific parser (ast module for Python, ts-morph for TypeScript)
    granularity: one of {function, class, file}, parsing level, default function
actions:
    parseFile: Parses single file into collection of CodeEntity objects
    parseRepository: Scans entire repository and returns ParsedCodeRepository
    enrichWithContext: Adds parent class/module context to function entities
    shouldIndex: Filters out private functions, trivial getters, or test helpers
    extractSignature: Generates function signature including parameter types
relations:
    @CodeEntity: produces code entity objects from parsed source code
    @ParsedCodeRepository: produces parsed repository structure from scanning codebase

entity: TraceLink
role: struct
purpose:
    - Represents discovered semantic relationship between fragments or entities across layers
    - Supports fine-grained fragment-to-fragment traceability enabling precise statement-level connections
    - Supports product-to-design, design-to-implementation, implementation-to-code, and all reverse directions
    - Created through hybrid approach combining embedding similarity and LLM reasoning
    - Includes human-readable explanation for why the connection exists
    - Stored in knowledge graph to enable bidirectional tracing across all layers
properties:
    sourceQualifiedName: String, source entity identifier (e.g., "NexusAssistant.PaymentFlow")
    sourceLayer: one of {product, design, implementation, code}, source layer
    targetQualifiedName: String, target entity identifier (e.g., "PaymentDesign.PaymentGateway" or "payment.gateway.PaymentService")
    targetLayer: one of {product, design, implementation, code}, target layer
    sourceFragmentId: String, optional fragment identifier for fine-grained traceability (e.g., "NexusAssistant.PaymentFlow.purpose.0.1")
    targetFragmentId: String, optional fragment identifier for fine-grained traceability
    confidence: Number, composite confidence score between 0.0 and 1.0 combining semantic similarity and LLM validation
    embeddingSimilarity: Number, raw cosine similarity score from fragment embedding comparison
    llmConfidence: Number, LLM reasoning confidence score for this connection
    rationale: String, human-readable explanation explaining why fragments are related and how they connect
    validationStatus: one of {validated, candidate, rejected}, LLM validation outcome
    direction: one of {forward, backward}, tracing direction relative to product-to-code flow
    discoveredTimestamp: Number, when link was generated
    embeddingModel: String, model used for semantic matching
    llmModel: String, LLM model used for validation and explanation

entity: TraceabilityMatcher
role: component
purpose:
    - Discovers implicit semantic relationships across all layers using hybrid approach combining embeddings and LLM reasoning
    - Creates fine-grained fragment embeddings for each statement, action, property, role, and code method enabling precise matching
    - Uses context enricher to generate rich fragment summaries including parent entity and referenced entities context
    - Generates embeddings from fragment content with entity context capturing complete architectural understanding
    - Uses semantic matcher for fast fragment embedding-based candidate generation
    - Applies LLM reasoner with enriched fragment context to validate candidates and discover non-obvious connections that embeddings miss
    - Generates human-readable explanations for trace links via explanation generator
    - Resolves ambiguities when multiple fragments appear similar using LLM contextual understanding
    - Discovers multi-hop trace paths through relationship chains that direct similarity cannot find
    - Persists discovered trace links via trace storage for instant loading on restart
    - Populates shared vectorStore enabling query processor to perform rapid semantic queries at fragment level
    - Stores discovered TraceLink objects with fragment IDs, confidence scores and explanations in knowledge graph
    - Maintains flexible traceability: product→design (required), design→implementation or design→code (alternative paths), implementation→code
properties:
    embeddingService: String, OpenAI API for text-embedding-3-small model
    embeddingDimensions: Number, vector size, 1536 for text-embedding-3-small
    embeddingSimilarityThreshold: Number, minimum cosine similarity for candidate generation, default 0.6
    llmConfidenceThreshold: Number, minimum LLM confidence for validated trace link, default 0.7
    llmModel: String, LLM for validation and reasoning, default gpt-4o-mini
    vectorStore: collection, stores fragment embeddings indexed by fragment_id and layer
    contentHashes: collection, tracks fragment content hashes for cache invalidation
actions:
    generateEmbedding: Calls embedding service to create vector representation of text
    createFragmentSummary: Formats fragment with parent entity context and referenced entities for embedding
    generateCodeFragments: Creates Fragment objects from CodeEntity for docstrings, signatures, and function bodies
    indexSpecFragment: Uses context enricher to gather complete fragment context with parent entity and referenced entities, then creates rich embedding from enriched summary
    indexCodeFragment: Uses context enricher to gather code fragment context including parent information and related specifications, then creates embedding from enriched summary
    findCandidates: Uses semantic matcher to find candidate fragment matches above embedding similarity threshold
    validateCandidate: Uses context enricher to get full enriched context for both fragments, then applies LLM reasoner to confirm if candidate trace link is valid
    disambiguateCandidates: Uses LLM reasoner to resolve ambiguity when multiple fragments have similar embeddings
    reasonAboutIndirectLinks: Uses LLM reasoner to follow relationship chains and discover multi-hop connections
    generateExplanation: Calls explanation generator to create rationale for trace link
    scoreConfidence: Uses trace validator to compute composite confidence from embedding similarity and LLM validation
    createTraceLink: Generates TraceLink with fragment IDs, confidence score, validation status, and human-readable rationale
    discoverLayerLinks: Discovers links following valid layer transitions using hybrid embedding + LLM approach with enriched fragment context
    discoverAllLinks: Checks trace storage cache validity, loads cached trace links if fragments unchanged, otherwise indexes all specification fragments and generates code fragments, creates embeddings for all fragments, discovers trace links across all layers with LLM validation then saves to cache
    populateVectorStore: Builds optimized vectorStore index for query processor with all fragment embeddings organized by layer and catalog
relations:
    @ContextEnricher: receives enriched fragment summaries from enricher for embedding generation
    @SemanticMatcher: receives candidate trace links from matcher for validation
    @LLMReasoner: sends candidates to reasoner for validation and indirect connection discovery
    @TraceValidator: sends trace links to validator for composite confidence scoring
    @ExplanationGenerator: sends validated trace links to generator for rationale creation
    @TraceStorage: saves and loads trace links to storage for persistence
    @EmbeddingCache: stores and retrieves embeddings from cache to avoid redundant API calls
    @KnowledgeGraph: stores discovered trace link objects in graph
    @QueryProcessor: populates vector store for query processor semantic search
    @Fragment: creates fragment objects for specification and code elements
    @CodeEntity: generates fragments from code entities
    @TraceLink: creates and stores trace link objects

entity: EmbeddingCache
role: component
purpose:
    - Caches generated embeddings by content hash to avoid redundant API calls
    - Implements full file reindex strategy with content-based caching for efficiency
    - Stores cache in memory with optional persistence to disk
properties:
    storageType: one of {memory, disk}, cache storage mechanism, default memory
    maxCacheSize: Number, maximum cached embeddings, default 10000
    cachePath: String, file path for persistent cache, used when storageType is disk
actions:
    getOrGenerate: Returns cached embedding if content unchanged, generates new one otherwise
    computeContentHash: Generates SHA256 hash of entity content for cache key
    invalidate: Removes cached embedding when source content changes
    persist: Writes in-memory cache to disk for persistence across restarts

entity: SemanticMatcher
role: component
purpose:
    - Provides fast embedding-based similarity matching at fragment level as first stage of trace discovery
    - Generates candidate trace links between fragments for validation
    - Uses vector search to find fragments above similarity threshold
properties:
    vectorStore: collection, indexed fragment embeddings organized by layer
    candidateThreshold: Number, minimum similarity for candidate generation, default 0.6
actions:
    findSimilarFragments: Performs cosine similarity search at fragment level filtered by valid target layers
    generateCandidates: Returns list of potential trace links between fragments above threshold with raw similarity scores
relations:
    @TraceabilityMatcher: provides candidate trace links to matcher for LLM validation

entity: LLMReasoner
role: component
purpose:
    - Applies large language model reasoning to validate trace links and discover non-obvious connections
    - Understands context, intent, and logical relationships beyond embedding similarity
    - Uses layer semantics to understand what each layer represents and expected transition patterns
    - Analyzes enriched entity context including purposes, properties, actions, related entities, and code behavior for validation
    - Follows chains of relationships to discover indirect multi-hop connections
properties:
    llmService: String, OpenAI API for chat completions
    llmModel: String, model for reasoning, default gpt-4o-mini
    validationPromptTemplate: String, structured prompt for trace validation including layer semantics
    reasoningTemperature: Number, LLM temperature for deterministic reasoning, default 0.1
    maxReasoningTokens: Number, token limit for LLM responses, default 500
actions:
    validateTraceLink: Analyzes enriched specification and code/spec context with layer semantics to confirm if candidate link is valid
    explainConnection: Generates detailed reasoning about why entities are related considering layer meanings
    disambiguateEntities: Determines correct match when multiple candidates have similar embeddings using layer-aware reasoning
    discoverIndirectLinks: Follows relationship chains to find multi-hop trace paths
    reasonAboutBehavior: Analyzes code logic flow to match against specification intent
    buildValidationPrompt: Constructs LLM prompt including enriched entity context and layer transition semantics
relations:
    @LayerSemantics: receives layer descriptions and transition semantics from layer semantics component

entity: TraceValidator
role: component
purpose:
    - Scores trace link confidence based on multiple quality signals
    - Identifies high-confidence traces and flags uncertain connections for review
    - Combines embedding similarity with LLM validation scores
properties:
    embeddingWeight: Number, weight for embedding similarity score, default 0.4
    llmWeight: Number, weight for LLM confidence score, default 0.6
    minCompositeConfidence: Number, minimum score for trace acceptance, default 0.7
actions:
    computeConfidence: Calculates weighted composite score from embedding and LLM signals
    assessQuality: Evaluates trace link against quality criteria
    flagForReview: Identifies low-confidence traces needing human validation
    categorizeConfidence: Assigns confidence level (high, medium, low) based on thresholds

entity: ExplanationGenerator
role: component
purpose:
    - Creates human-readable justifications explaining why trace links exist
    - Helps developers understand traceability rationale, not just see connections
    - Generates context-aware explanations based on entity semantics and LLM reasoning
properties:
    llmService: String, OpenAI API for explanation generation
    llmModel: String, model for natural language generation, default gpt-4o-mini
    explanationTemplate: String, template for structured rationale generation
    maxExplanationLength: Number, character limit for explanations, default 500
actions:
    generateRationale: Creates explanation describing why specification connects to code
    describeConnection: Explains how entities relate based on purposes, properties, and actions
    formatExplanation: Structures rationale in readable format with key evidence points

entity: ContextEnricher
role: component
purpose:
    - Enriches fragment context by gathering parent entity and referenced entities from knowledge graph
    - Generates layer-specific semantic context explaining what each layer represents
    - Creates comprehensive fragment summaries including parent entity role and referenced entity context
    - Provides enriched context for both embedding generation and LLM validation
properties:
    maxRelatedEntities: Number, maximum number of related entities to include, default 5
    includeRelationships: Boolean, whether to include entity relationships in enriched context, default true
    relationshipDepth: Number, how many hops to traverse for related entities, default 1
actions:
    enrichSpecFragment: Gathers complete context for specification fragment including parent entity, referenced entities, layer semantics, and architectural role
    enrichCodeFragment: Gathers complete context for code fragment including parent code entity, file location, and related specifications if available
    getLayerSemantics: Retrieves layer description and semantics for specific layer
    getRelatedEntityContext: Queries knowledge graph to get related entities and their relationship types
    formatEnrichedSummary: Structures enriched fragment context into text format suitable for embedding or LLM consumption
relations:
    @KnowledgeGraph: retrieves entities and fragments from graph for context enrichment
    @LayerSemantics: receives layer descriptions and transition semantics from layer semantics component

entity: LayerSemantics
role: component
purpose:
    - Provides semantic descriptions of what each layer represents in the system
    - Defines valid layer transitions and what they mean
    - Supplies validation criteria specific to each layer transition type
    - Used by context enricher and LLM reasoner to understand layer semantics
properties:
    layerDescriptions: collection, maps layer names to semantic descriptions explaining what each layer represents
    transitionTemplates: collection, describes expected relationships between each valid layer pair
    validationCriteria: collection, layer-specific criteria for validating trace links
    validTransitions: collection, defines which layer transitions are valid (product→design, design→implementation, design→code, implementation→code)
actions:
    getLayerDescription: Returns semantic description of what a specific layer represents
    getTransitionSemantics: Returns description of expected relationship between source and target layers
    getValidationCriteria: Returns criteria for validating trace links for specific layer transition
    isValidTransition: Checks if transition between two layers is valid
relations:
    @ContextEnricher: provides layer descriptions and semantics to context enricher
    @LLMReasoner: provides layer descriptions and transition patterns to LLM reasoner

entity: TraceStorage
role: component
purpose:
    - Persists discovered TraceLink objects to disk for instant loading on restart
    - Tracks SHA256 content hashes of fragment content to detect specification or code changes
    - Invalidates entire trace link cache when any fragment is added, removed, or modified triggering full re-discovery
    - Eliminates expensive LLM validation re-runs when nothing has changed
    - Works with embedding cache which retains embeddings for unchanged fragments enabling efficient re-discovery
    - Stores cache in .trace_cache directory with JSON serialization
    - Maintains cache version to detect incompatible format changes and auto-clear outdated cache
    - Cache version 2.0 for fragment-based embeddings, auto-clears v1.0 entity-based cache
properties:
    storagePath: String, directory for cache files, default .trace_cache
    traceLinksFile: String, JSON file for serialized TraceLink collection
    contentHashesFile: String, JSON file storing fragment content hashes for change detection
    versionFile: String, text file storing cache format version for migration detection
    cacheVersion: String, current cache format version, 2.0 for fragment-based embeddings
    enabled: Boolean, enables trace link persistence, default true
actions:
    saveTraceLinks: Persists collection of TraceLink objects with fragment content hashes and version to disk
    loadTraceLinks: Loads cached trace links and content hashes from disk if files exist
    isCacheValid: Compares current fragment content hashes against cached hashes to detect changes
    computeEntityHash: Generates SHA256 hash of fragment content for change detection
    clearCache: Removes all cached trace links and content hashes
    getCacheStats: Returns statistics about cached trace links including count and file size
    checkAndMigrateCache: Detects cache format version, auto-clears if outdated or incompatible with current version
    writeVersion: Persists current cache format version to disk for future migration detection
relations:
    @TraceLink: persists and loads trace link objects to disk
    @EmbeddingCache: works with embedding cache to enable efficient re-discovery after changes


scenario: DiscoverEntitiesInCatalog
User queries "List all entities in NexusAssistant catalog"
@QueryProcessor parses intent and identifies catalog filter.
@QueryProcessor calls @KnowledgeGraph getEntities with catalog="NexusAssistant".
@KnowledgeGraph returns all entities from that catalog with roles and brief purposes.
@QueryProcessor formats results grouped by layer and returns as JSON.

scenario: FilterEntitiesBySemanticContext
User queries "Find entities related to parsing"
@QueryProcessor generates embedding for "parsing" using embeddingService.
@QueryProcessor performs semantic search across all fragment embeddings in @KnowledgeGraph.
@Fragment objects from entities like @NexusParser, @CodeParser, and @ValidationEngine match above semantic threshold.
@QueryProcessor returns matched fragments with parent entity context, confidence scores and explains their parsing capabilities.

scenario: ExploreEntityWithRelationships
User queries "Show details for NexusParser entity"
@QueryProcessor calls @KnowledgeGraph getEntity("NexusParser").
@QueryProcessor retrieves entity definition with purpose, properties, and actions.
@QueryProcessor calls @KnowledgeGraph getRelations("NexusParser") to get all relationships.
Results include complete entity structure plus related entities like @ValidationEngine, @KnowledgeGraph, and @ParsedSpecification.
@QueryProcessor returns full entity context enabling deeper exploration.

scenario: BrowseEntitiesByLayer
User queries "Show all design layer entities"
@QueryProcessor identifies layer filter from query intent.
@QueryProcessor calls @KnowledgeGraph getEntities with layer="design".
@KnowledgeGraph returns entities from design catalogs (architecture files).
@QueryProcessor groups results by catalog and includes entity counts.
Results show complete design layer structure across all architectural specifications.

scenario: FilterEntitiesByRole
User queries "Find all components"
@QueryProcessor recognizes role filter in query.
@QueryProcessor calls @KnowledgeGraph filterEntitiesByRole("component").
@KnowledgeGraph returns entities where role="component" across all catalogs.
Results include @QueryProcessor, @MCPServer, @ValidationEngine, @CodeParser, @TraceabilityMatcher, @EmbeddingCache.
@QueryProcessor formats results showing how components interact in system architecture.

scenario: ExploreSystemOverview
User requests system overview without specific query
@QueryProcessor calls @KnowledgeGraph getCatalogs to list all catalogs.
@KnowledgeGraph returns catalog statistics with entity counts per layer.
@QueryProcessor identifies key entities in each catalog based on relation counts.
Results provide high-level map of system structure with entry points for further exploration.

scenario: AccurateContextualFragmentRetrieval
User queries "What entities are involved in processing payment transactions?"
@QueryProcessor calls semanticSearch which generates multiple query candidates using LLM: "entities process payment transactions", "payment transaction processing", "entities involved in payments".
@QueryProcessor generates embeddings for all query candidates using embeddingService via @EmbeddingCache (cached if query seen before).
Searches pre-indexed fragmentEmbeddings (populated by @TraceabilityMatcher) comparing each candidate embedding against all fragment embeddings.
Computes cosine similarity for every candidate-fragment pair to ensure no relevant matches are missed.
Applies semanticThreshold=0.6 to filter candidates, tuned to favor recall over premature filtering.
Fragments matching any query candidate above threshold are collected, deduplicating by keeping highest similarity per fragment.
@QueryProcessor retrieves matching fragments from @KnowledgeGraph: PaymentFlow, PaymentGateway, PaymentService, TransactionValidator fragments.
Sorts fragments by similarity score descending, enriches each with parent entity data and referenced entities data.
Returns complete, accurate ranked fragments with parent entity context, referenced entities, matched candidate, and similarity scores.

scenario: DeepSemanticUnderstanding
User asks "Which features help users recover from errors?"
@QueryProcessor semanticSearch generates query candidates capturing semantic meaning of "error recovery".
@QueryProcessor searches fragmentEmbeddings comparing each candidate embedding against all fragment embeddings.
@QueryProcessor identifies semantic matches at statement level beyond keyword matching:
    - Action fragments with "retry", "rollback", "validation" match "recover from errors" semantically
    - Purpose fragments with "error handling", "resilience" match even without exact term "recover"
    - @ValidationEngine purpose fragment matches (0.73 similarity) due to error detection and reporting capabilities
@QueryProcessor retrieves matched fragments with full parent entity details from @KnowledgeGraph including complete entity context.
@QueryProcessor examines entity relationships to find connected error management entities.
Results include precise matching fragments with parent entities from multiple layers explaining complete error recovery ecosystem with semantic reasoning.

scenario: CompleteCrossLayerSearch
User queries "What defines and implements user authentication?"
@QueryProcessor calls semanticSearch multiple times, once per layer to search across layers.
First call: semanticSearch with layer="product" generates query candidates and finds authentication feature fragments.
Second call: semanticSearch with layer="design" generates query candidates and finds authentication component fragments.
Third call: semanticSearch with layer="code" (if enabled) finds authentication code fragments.
Each search generates query candidates, creates embeddings, searches fragmentEmbeddings for that layer.
Each search returns fragments with parent entity data and referenced entities.
User can then call traceToCode or traceToSpec to follow @TraceLink objects between matched entities.
@KnowledgeGraph provides trace connections showing product→design→code relationships.
Returns fragments from multiple layers with parent entity context and referenced entities for complete cross-layer understanding.

scenario: SimpleFragmentRanking
@QueryProcessor semanticSearch receives multiple matching fragments with similarity scores from query candidate matching.
For fragments matching multiple query candidates, keeps only the highest similarity score per fragment during deduplication.
@QueryProcessor sorts fragments by similarity score descending (simple ranking by cosine similarity).
Formats results with parent entity data retrieved from @KnowledgeGraph for each fragment.
Includes referenced entities data for each fragment showing related specifications.
Example: PaymentGateway action fragment with similarity 0.82 to "payment transaction processing" candidate ranked higher than fragment with 0.71.
Results show most semantically similar fragments first with parent entity context, referenced entities, and matched query candidate for transparency.

scenario: CachedIterativeSearch
User performs sequence: "Find payment entities" → explores PaymentGateway → "Find payment processors".
First query: @QueryProcessor semanticSearch generates query candidates and embeddings, searches fragmentEmbeddings for payment-related fragments.
Returns PaymentGateway fragments with parent entity context and referenced entities.
@EmbeddingCache stores generated embeddings for reuse across queries.
User explores PaymentGateway: @QueryProcessor exploreEntity retrieves complete entity details from @KnowledgeGraph with properties, actions, and relationships.
Second query "Find payment processors": @QueryProcessor semanticSearch generates new query candidates and embeddings.
@EmbeddingCache returns cached embeddings for any previously seen query phrases, avoiding redundant API calls.
Fragment embeddings remain loaded in fragmentEmbeddings dict for fast similarity computation.
@EmbeddingCache hit rate improves with repeated similar queries enabling efficient discovery.

scenario: SpecificationUpdate
Developer modifies a .nxs file. 
@SpecificationStore detects the change and triggers @NexusParser to re-parse the file.
@KnowledgeGraph updates affected entities and relations to reflect the changes.

scenario: QueryingSpecifications
AI coding assistant queries @NexusAssistantService through @APIGateway.
@QueryProcessor searches @KnowledgeGraph for relevant entities and relationships, then returns results as structured JSON.

scenario: SystemInitialization
On startup, @SpecificationStore loads all .nxs files from configured directories.
@NexusParser parses each file in parallel. 
@KnowledgeGraph builds the complete entity relationship graph with three-layer model. 
@APIGateway and @MCPServer become ready to serve requests.

scenario: MCPAgentIntegration
External AI agent connects to @NexusAssistantService through @MCPServer using MCP protocol.
Agent discovers available tools exposed by @MCPServer.
Agent requests specification context via MCP tool call.
@MCPServer routes request to @QueryProcessor, which queries @KnowledgeGraph.
Results are formatted by @MCPServer as MCP response and returned to agent.

scenario: CodeRepositoryIndexing
Developer configures code repository path in @NexusAssistantService.
@CodeParser scans repository and parses source files using language-specific AST parser.
For each file, @CodeParser extracts classes and functions into @CodeEntity objects.
@CodeParser enriches entities with parent context and filters out trivial/private functions.
@ParsedCodeRepository is created with all @CodeEntity objects and stored in @KnowledgeGraph.

scenario: EnrichedFragmentEmbeddingGeneration
@TraceabilityMatcher begins indexing specification fragments from design layer entity.
@TraceabilityMatcher iterates through entity's purpose fragments, property fragments, and action fragments.
For each fragment, @TraceabilityMatcher calls @ContextEnricher enrichSpecFragment with fragment, parent entity, catalog, layer, and @KnowledgeGraph.
@ContextEnricher calls @LayerSemantics getLayerDescription("design") receiving: "Describes HOW the system is organized, technical architecture, services, components".
@ContextEnricher retrieves parent entity details including role and other fragments from @KnowledgeGraph.
@ContextEnricher identifies referenced entities from fragment's referencedEntities list.
@ContextEnricher formats enriched fragment summary including: fragment type and content, layer semantics, parent entity name and role, referenced entity names and their purposes, architectural context.
@TraceabilityMatcher receives enriched summary from @ContextEnricher (significantly richer than simple fragment text alone).
@TraceabilityMatcher generates embedding for enriched fragment summary capturing full statement-level context with architectural understanding.
Embedding now encodes: what layer means, fragment's precise semantics, parent entity context, referenced entity relationships, architectural role.
When compared to code fragment embeddings, similarity matching captures semantic connections at statement level with complete context.

scenario: LLMEnhancedFragmentTraceabilityDiscovery
After specifications and code are loaded into @KnowledgeGraph, @TraceabilityMatcher begins hybrid discovery process at fragment level.
For each specification fragment in each layer, @TraceabilityMatcher uses @ContextEnricher to create enriched fragment summary then generates embedding using OpenAI API.
@EmbeddingCache checks if embedding already exists for this fragment content hash, returns cached or generates new.
For each @CodeEntity, @TraceabilityMatcher first generates code fragments (docstring, signature, body) then creates embeddings for each fragment.
@SemanticMatcher performs cosine similarity search at fragment level following valid layer transitions to generate candidates:
    - Product layer fragments compared to design layer fragments (always)
    - Design layer fragments compared to both implementation layer fragments AND code fragments (alternative paths)
    - Implementation layer fragments compared to code fragments (when implementation specs exist)
Candidate fragment pairs above embeddingSimilarityThreshold (default 0.6) are passed to @LLMReasoner for validation.
@LLMReasoner analyzes each candidate pair by reading fragment content, parent entity context, and referenced entities.
@LLMReasoner validates if semantic connection between fragments is logically sound or discovers why embeddings found false positive.
@LLMReasoner identifies additional connections through multi-hop reasoning that embeddings missed.
@ExplanationGenerator creates human-readable rationale for each validated trace explaining the fragment-level connection.
@TraceValidator computes composite confidence score (0.4 * embedding_similarity + 0.6 * llm_confidence).
When composite confidence exceeds threshold (default 0.7), @TraceLink is created with source and target fragment IDs, validation status and explanation.
All @TraceLink objects stored in @KnowledgeGraph with fragment IDs, confidence scores, rationales, and validation status.
@QueryProcessor can traverse @TraceLink objects to trace across layers at fragment level with explainable connections users can trust.

scenario: DisambiguatingMultipleCandidates
@TraceabilityMatcher discovers three design entities with similar embeddings (0.72, 0.71, 0.70) to PaymentService code.
@SemanticMatcher generates all three as candidates: PaymentGateway, PaymentProcessor, PaymentValidator.
@LLMReasoner receives candidates with full specification contexts and PaymentService code.
@LLMReasoner analyzes PaymentService code behavior: processes transactions, validates cards, handles errors.
@LLMReasoner examines each specification's purpose and actions for logical match.
@LLMReasoner determines PaymentGateway (external integration focus) best matches code's transaction processing.
@LLMReasoner rejects PaymentProcessor (internal logic orchestration) and PaymentValidator (validation only).
@ExplanationGenerator creates rationale: "PaymentService implements PaymentGateway because code handles external API calls, matches gateway's process action, and manages transaction lifecycle as specified."
@TraceValidator computes high LLM confidence (0.85) despite similar embedding scores.
@TraceLink created for PaymentGateway→PaymentService with composite confidence 0.79 and clear explanation.
False positives prevented - developers see correct, explainable trace link.

scenario: DiscoveringIndirectLinks
Product requirement UserAuthentication doesn't mention specific implementation details.
@SemanticMatcher finds low embedding similarity (0.58) to auth_handler.py code, below candidate threshold.
@LLMReasoner examines UserAuthentication relationships in @KnowledgeGraph.
@LLMReasoner finds UserAuthentication traces to AuthService design entity (high confidence).
@LLMReasoner analyzes AuthService specification and finds strong semantic match to auth_handler.py.
@LLMReasoner reasons through chain: UserAuthentication→AuthService→auth_handler.py.
@TraceabilityMatcher creates multi-hop @TraceLink path with explanations at each step.
@ExplanationGenerator describes full chain rationale showing how product requirement flows through design to code.
Developer queries UserAuthentication and sees complete implementation path despite no direct similarity.
Multi-hop reasoning reveals connections pure embedding search cannot find.

scenario: ExplainingTraceRationale
Developer views trace link from PaymentFlow specification to payment_processor.py code.
Developer requests explanation for why this connection exists.
@QueryProcessor retrieves @TraceLink from @KnowledgeGraph including stored rationale.
Rationale generated by @ExplanationGenerator during discovery explains:
    "payment_processor.py implements PaymentFlow specification because:
    1. Code's process_payment function fulfills PaymentFlow's processTransaction action
    2. Error handling in code matches PaymentFlow's recovery requirements
    3. Code validates payment methods as specified in PaymentFlow properties
    4. Transaction state management aligns with PaymentFlow's flow semantics
    Confidence: 0.83 (embedding: 0.74, LLM validation: 0.89)"
Developer understands traceability rationale and trusts the connection.
Explanation enables informed decisions about code changes and their impact on requirements.

scenario: ForwardTracing
Developer queries "what code implements PaymentGateway specification?"
@QueryProcessor identifies PaymentGateway entity in @KnowledgeGraph design layer.
@QueryProcessor calls getTraceLinks with forward direction to find code implementations.
@KnowledgeGraph returns @TraceLink objects pointing to @CodeEntity objects with confidence scores and explanations.
@QueryProcessor retrieves full @CodeEntity details including file paths and line numbers.
Results returned as JSON showing matched code with confidence scores, validation status, and human-readable rationales.

scenario: BackwardTracing
Developer views payment_service.py file and queries "why does this code exist?"
@QueryProcessor extracts @CodeEntity objects for functions in that file from @KnowledgeGraph.
@QueryProcessor calls getTraceLinks with backward direction starting from code layer.
@KnowledgeGraph returns @TraceLink objects from code to implementation layer specifications.
@QueryProcessor follows next @TraceLink objects from implementation to design layer.
@QueryProcessor follows final @TraceLink objects from design to product layer.
Results show complete chain: code ← implementation spec ← design spec ← product requirement.
Each link includes confidence score and rationale explaining the connection.
Developer sees full business justification and architectural reasoning for the code.

scenario: FullChainTracingWithImplementation
Product manager defines PaymentFlow requirement in product layer.
Developer queries "how is PaymentFlow implemented?"
@QueryProcessor finds PaymentFlow entity in product layer of @KnowledgeGraph.
@QueryProcessor traverses @TraceLink from product to design layer, finds PaymentGateway entity.
@QueryProcessor traverses @TraceLink from design to implementation layer, finds PaymentService component spec.
@QueryProcessor traverses @TraceLink from implementation to code, finds payment.gateway.PaymentService.process_payment function.
Results show complete forward chain: product requirement → design architecture → implementation spec → actual code.
Each hop includes the traced entity, confidence score, and rationale for connection.

scenario: DirectDesignToCodeTracing
Product manager defines SearchFeature requirement in product layer.
Developer queries "how is SearchFeature implemented?"
@QueryProcessor finds SearchFeature entity in product layer of @KnowledgeGraph.
@QueryProcessor traverses @TraceLink from product to design layer, finds SearchAPI entity.
@QueryProcessor checks for implementation layer links but finds none (design is detailed enough).
@QueryProcessor traverses @TraceLink directly from design to code, finds search.api.SearchService.search function.
Results show shorter chain: product requirement → design architecture → actual code (skipping implementation layer).
This path is used when design specifications are detailed enough and no separate implementation spec exists.

scenario: CodeChangeReindexing
Developer modifies payment_service.py file, @SpecificationStore detects change.
@CodeParser re-parses the modified file into new @CodeEntity objects.
@KnowledgeGraph removes old code entities from that file using remove_code_entities_by_file.
@EmbeddingCache checks content hashes - unchanged functions keep cached embeddings.
@TraceabilityMatcher regenerates embeddings only for modified functions using @EmbeddingCache.
@TraceabilityMatcher recomputes @TraceLink objects for changed entities and updates @KnowledgeGraph.
Queries immediately reflect updated traceability without full system reindex.

scenario: SemanticNaturalLanguageQuery
User submits natural language query "What components are responsible for parsing specifications?"
@QueryProcessor receives query and checks semanticSearchEnabled property.
@QueryProcessor calls generateQueryCandidates using @llmModel to transform question into declarative search phrases: ["components parse specifications", "specification parsing components", "parsing specifications responsibility", "components responsible for parsing"].
@QueryProcessor generates embeddings for all query candidates using embeddingService (OpenAI API).
@EmbeddingCache checks if candidate embeddings were cached, returns cached or generates new.
@QueryProcessor retrieves all fragment embeddings from @KnowledgeGraph (previously indexed by @TraceabilityMatcher).
@QueryProcessor computes cosine similarity between each candidate embedding and each fragment embedding.
Fragments with similarity above semanticThreshold (default 0.6) to any candidate are collected with highest similarity score kept per fragment.
@QueryProcessor deduplicates results by fragment ID, keeping maximum similarity across all candidates.
@QueryProcessor ranks results by similarity score descending using parent entity richness and centrality.
Results include purpose and action fragments from @NexusParser, @ValidationEngine, @CodeParser with parent entity data and referenced entities.
@QueryProcessor returns top maxResults (default 10) as JSON with fragment details, parent entity context, referenced entities, matched candidate, and relevance scores.

scenario: StructuralLayerFiltering
User queries "Find all entities in the design layer"
@QueryProcessor discoverEntities is called with layer="design" filter and no semantic context.
Since no context is provided, uses structural filtering path instead of semantic search.
@QueryProcessor calls @KnowledgeGraph getEntities with layer filter "design".
All design layer entities returned directly without embedding computation or query candidate generation.
Results formatted with entity names, catalogs, roles, and layers for browsing.

scenario: FuzzyConceptMatching
User asks "What handles file watching?" without knowing exact entity name.
@QueryProcessor calls generateQueryCandidates transforming question into: ["file watching handler", "handles file watching", "monitors file changes", "file change detection"].
@QueryProcessor generates embeddings for all candidates using embeddingService.
Candidate embeddings compared against all fragment embeddings in @KnowledgeGraph.
@SpecificationStore purpose fragment has high semantic similarity to "monitors file changes" candidate containing "watches for file changes".
@SpecificationStore action fragment "watchFile: Monitors file for changes" matches strongly to "file change detection" candidate.
Fragments exceed semanticThreshold (0.6), ranked highest due to precise statement-level match with multiple candidates.
@QueryProcessor returns matched fragments with parent entity @SpecificationStore data and referenced entities, confidence 0.82, showing exact matched statements plus matched candidate that triggered each result for transparency.

scenario: SharedEmbeddingInfrastructure
@QueryProcessor and @TraceabilityMatcher both initialize with same embeddingService (OpenAI API).
Both components share single @EmbeddingCache instance configured in @NexusAssistantService.
@TraceabilityMatcher indexes all specification fragments during TraceabilityDiscovery scenario.
Fragment embeddings stored in cache with fragment content hashes as keys.
When @QueryProcessor performs semantic search, it reuses fragment embeddings created by @TraceabilityMatcher.
No duplicate embedding generation for specification fragments - cache provides efficiency.
Only query embeddings are newly generated per search request.
